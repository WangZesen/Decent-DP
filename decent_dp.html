

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>decent_dp package &mdash; Decent-DP  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
    <link rel="shortcut icon" href="_static/icon.ico"/>
    <link rel="canonical" href="https://wangzesen.github.io/Decent-DP/decent_dp.html" />
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=5929fcd5"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Algorithm schemas" href="schema.html" />
    <link rel="prev" title="decent_dp" href="modules.html" />
    <link href="_static/style.css" rel="stylesheet" type="text/css">

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Decent-DP
              <img src="_static/icon-light.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">API Documentation</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">decent_dp package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-decent_dp.ddp">decent_dp.ddp module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#decent_dp.ddp.DecentralizedDataParallel"><code class="docutils literal notranslate"><span class="pre">DecentralizedDataParallel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#decent_dp.ddp.OPTIM_FN_TYPE"><code class="docutils literal notranslate"><span class="pre">OPTIM_FN_TYPE</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-decent_dp.optim">decent_dp.optim module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#decent_dp.optim.AccumAdam"><code class="docutils literal notranslate"><span class="pre">AccumAdam</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#decent_dp.optim.AccumAdamW"><code class="docutils literal notranslate"><span class="pre">AccumAdamW</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#decent_dp.optim.lr_scheduler_fn_cosine_with_warmup"><code class="docutils literal notranslate"><span class="pre">lr_scheduler_fn_cosine_with_warmup()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#decent_dp.optim.optim_fn_accum_adam"><code class="docutils literal notranslate"><span class="pre">optim_fn_accum_adam()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#decent_dp.optim.optim_fn_accum_adamw"><code class="docutils literal notranslate"><span class="pre">optim_fn_accum_adamw()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#decent_dp.optim.optim_fn_adam"><code class="docutils literal notranslate"><span class="pre">optim_fn_adam()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#decent_dp.optim.optim_fn_adamw"><code class="docutils literal notranslate"><span class="pre">optim_fn_adamw()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-decent_dp.topo">decent_dp.topo module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#decent_dp.topo.Edge"><code class="docutils literal notranslate"><span class="pre">Edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#decent_dp.topo.Topology"><code class="docutils literal notranslate"><span class="pre">Topology</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#decent_dp.topo.TopologyReg"><code class="docutils literal notranslate"><span class="pre">TopologyReg</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-decent_dp.utils">decent_dp.utils module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#decent_dp.utils.initialize_dist"><code class="docutils literal notranslate"><span class="pre">initialize_dist()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#module-decent_dp">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="schema.html">Algorithm Schema</a></li>
<li class="toctree-l1"><a class="reference internal" href="topology.html">Communication Topology</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">Benchmark Tests</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Decent-DP</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="modules.html">decent_dp</a></li>
      <li class="breadcrumb-item active">decent_dp package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/decent_dp.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="decent-dp-package">
<h1>decent_dp package<a class="headerlink" href="#decent-dp-package" title="Link to this heading"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading"></a></h2>
</section>
<section id="module-decent_dp.ddp">
<span id="decent-dp-ddp-module"></span><h2>decent_dp.ddp module<a class="headerlink" href="#module-decent_dp.ddp" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="decent_dp.ddp.DecentralizedDataParallel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">decent_dp.ddp.</span></span><span class="sig-name descname"><span class="pre">DecentralizedDataParallel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optim_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Optimizer</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_scheduler_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Optimizer</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">LRScheduler</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topology</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'complete'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scaler</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">GradScaler</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_clip_norm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_as_bucket_view</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_buffer_in_global_avg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bucket_size_in_mb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_local_world_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/decent_dp/ddp.html#DecentralizedDataParallel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.ddp.DecentralizedDataParallel" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Decentralized data parallel wrapper for PyTorch module</p>
<ol class="arabic simple">
<li><p>The wrapper places hooks during the backward pass to trace the order of used parameters in the first iteration, and     2. Split the parameters into buckets and create optimizers and LR schedulers for each bucket,         Add hooks on the last parameter of each bucket to perform the bucket-wise update and communication,     3. During the backward passes in the training loop, the hooks are triggered to perform the bucket-wise update and communication</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Warning<span class="colon">:</span></dt>
<dd class="field-odd"><p>The wrapper currently does not support “channels_last” memory format</p>
</dd>
<dt class="field-even">Warning<span class="colon">:</span></dt>
<dd class="field-even"><p>The wrapper assumes that the parameter will only be used once in the backward pass</p>
</dd>
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>Module</em>) – PyTorch module to be wrapped</p></li>
<li><p><strong>optim_fn</strong> (<em>OPTIM_FN_TYPE</em>) – Function to create the optimizer, which takes a list of tuples of parameters and their names</p></li>
<li><p><strong>lr_scheduler_fn</strong> (<em>Optional</em><em>[</em><em>LR_SCHEDULER_FN_TYPE</em><em>]</em><em>, </em><em>optional</em>) – Function to create the learning rate scheduler,             which takes the optimizer as input. Defaults to None.</p></li>
<li><p><strong>topology</strong> (<em>str</em><em>, </em><em>optional</em>) – Topology of the decentralized communication graph. Defaults to ‘complete’.</p></li>
<li><p><strong>scaler</strong> (<em>Optional</em><em>[</em><em>GradScaler</em><em>]</em><em>, </em><em>optional</em>) – Gradient scaler for mixed precision training. Defaults to None.</p></li>
<li><p><strong>grad_clip_norm</strong> (<em>float</em><em>, </em><em>optional</em>) – Gradient clipping norm, set to 0.0 if no gradient clipping is applied. Defaults to 0.0.</p></li>
<li><p><strong>param_as_bucket_view</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use the parameter as a view of part of the contiguous buffer. Defaults to True.</p></li>
<li><p><strong>sync_buffer_in_global_avg</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to synchronize the float buffers in the global average. Defaults to False.</p></li>
<li><p><strong>bucket_size_in_mb</strong> (<em>int</em><em>, </em><em>optional</em>) – Size of the bucket in MB. Defaults to 25 MB.</p></li>
<li><p><strong>local_world_size</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>) – Provide the local world size if not using the environment variable. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="decent_dp.ddp.DecentralizedDataParallel.FLOAT_DTYPES">
<span class="sig-name descname"><span class="pre">FLOAT_DTYPES</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">[torch.float16,</span> <span class="pre">torch.float32,</span> <span class="pre">torch.float64]</span></em><a class="headerlink" href="#decent_dp.ddp.DecentralizedDataParallel.FLOAT_DTYPES" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="decent_dp.ddp.DecentralizedDataParallel.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/decent_dp/ddp.html#DecentralizedDataParallel.eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.ddp.DecentralizedDataParallel.eval" title="Link to this definition"></a></dt>
<dd><p>Set the module in evaluation mode</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="decent_dp.ddp.DecentralizedDataParallel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/decent_dp/ddp.html#DecentralizedDataParallel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.ddp.DecentralizedDataParallel.forward" title="Link to this definition"></a></dt>
<dd><p>Forward pass of the model</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="decent_dp.ddp.DecentralizedDataParallel.global_avg">
<span class="sig-name descname"><span class="pre">global_avg</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/decent_dp/ddp.html#DecentralizedDataParallel.global_avg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.ddp.DecentralizedDataParallel.global_avg" title="Link to this definition"></a></dt>
<dd><p>Perform global average on the parameters (and buffers if sync_buffer_in_global_avg is True)
The function is called at the end of the training loop to synchronize the parameters across all nodes for evaluation</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="decent_dp.ddp.DecentralizedDataParallel.named_parameters">
<span class="sig-name descname"><span class="pre">named_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Parameter</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/decent_dp/ddp.html#DecentralizedDataParallel.named_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.ddp.DecentralizedDataParallel.named_parameters" title="Link to this definition"></a></dt>
<dd><p>Get the named parameters of the model</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="decent_dp.ddp.DecentralizedDataParallel.parameters">
<span class="sig-name descname"><span class="pre">parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Parameter</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/decent_dp/ddp.html#DecentralizedDataParallel.parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.ddp.DecentralizedDataParallel.parameters" title="Link to this definition"></a></dt>
<dd><p>Get the parameters of the model</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to get the parameters recursively. Defaults to True.</p>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Iterator[Parameter]</em> – The iterator of the parameters</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="decent_dp.ddp.DecentralizedDataParallel.set_accumulate_grad">
<span class="sig-name descname"><span class="pre">set_accumulate_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">enable</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/decent_dp/ddp.html#DecentralizedDataParallel.set_accumulate_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.ddp.DecentralizedDataParallel.set_accumulate_grad" title="Link to this definition"></a></dt>
<dd><p>Set the gradient accumulation mode</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>enable</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to accumulate the gradients. Defaults to True.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="decent_dp.ddp.DecentralizedDataParallel.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/decent_dp/ddp.html#DecentralizedDataParallel.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.ddp.DecentralizedDataParallel.train" title="Link to this definition"></a></dt>
<dd><p>Set the module in training mode</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to set the module in training mode. Defaults to True.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py data">
<dt class="sig sig-object py" id="decent_dp.ddp.OPTIM_FN_TYPE">
<span class="sig-prename descclassname"><span class="pre">decent_dp.ddp.</span></span><span class="sig-name descname"><span class="pre">OPTIM_FN_TYPE</span></span><a class="headerlink" href="#decent_dp.ddp.OPTIM_FN_TYPE" title="Link to this definition"></a></dt>
<dd><p>Data type for the learning rate scheduler function</p>
<p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]], <code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code>]</p>
</dd></dl>

</section>
<section id="module-decent_dp.optim">
<span id="decent-dp-optim-module"></span><h2>decent_dp.optim module<a class="headerlink" href="#module-decent_dp.optim" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="decent_dp.optim.AccumAdam">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">decent_dp.optim.</span></span><span class="sig-name descname"><span class="pre">AccumAdam</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">betas</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">(0.9,</span> <span class="pre">0.999)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3.0517578125e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accum_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/decent_dp/optim.html#AccumAdam"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.optim.AccumAdam" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></p>
<p>AccumAdamW optimizer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>Any</em>) – parameters list or groups</p></li>
<li><p><strong>lr</strong> (<em>float</em><em>, </em><em>optional</em>) – base learning rate. Defaults to 1e-3.</p></li>
<li><p><strong>betas</strong> (<em>Tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>, </em><em>optional</em>) – beta1 and beta2. Defaults to (0.9, 0.999).</p></li>
<li><p><strong>eps</strong> (<em>float</em><em>, </em><em>optional</em>) – epsilon. Defaults to 1e-8.</p></li>
<li><p><strong>weight_decay</strong> (<em>float</em><em>, </em><em>optional</em>) – weight decay. Defaults to 0.</p></li>
<li><p><strong>accum_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – number of accumulation steps. Defaults to 4. should be scaling up with the number of workers.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="decent_dp.optim.AccumAdam.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/decent_dp/optim.html#AccumAdam.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.optim.AccumAdam.step" title="Link to this definition"></a></dt>
<dd><p>Perform a single optimization step to update parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>closure</strong> (<em>Callable</em>) – A closure that reevaluates the model and
returns the loss. Optional for most optimizers.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="decent_dp.optim.AccumAdamW">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">decent_dp.optim.</span></span><span class="sig-name descname"><span class="pre">AccumAdamW</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">betas</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">(0.9,</span> <span class="pre">0.999)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accum_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/decent_dp/optim.html#AccumAdamW"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.optim.AccumAdamW" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></p>
<p>AccumAdamW optimizer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>Any</em>) – parameters list or groups</p></li>
<li><p><strong>lr</strong> (<em>float</em><em>, </em><em>optional</em>) – base learning rate. Defaults to 1e-3.</p></li>
<li><p><strong>betas</strong> (<em>Tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>, </em><em>optional</em>) – beta1 and beta2. Defaults to (0.9, 0.999).</p></li>
<li><p><strong>eps</strong> (<em>float</em><em>, </em><em>optional</em>) – epsilon. Defaults to 1e-8.</p></li>
<li><p><strong>weight_decay</strong> (<em>float</em><em>, </em><em>optional</em>) – weight decay. Defaults to 0.</p></li>
<li><p><strong>accum_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – number of accumulation steps. Defaults to 4. should be scaling up with the number of workers.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="decent_dp.optim.AccumAdamW.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/decent_dp/optim.html#AccumAdamW.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.optim.AccumAdamW.step" title="Link to this definition"></a></dt>
<dd><p>Perform a single optimization step to update parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>closure</strong> (<em>Callable</em>) – A closure that reevaluates the model and
returns the loss. Optional for most optimizers.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="decent_dp.optim.lr_scheduler_fn_cosine_with_warmup">
<span class="sig-prename descclassname"><span class="pre">decent_dp.optim.</span></span><span class="sig-name descname"><span class="pre">lr_scheduler_fn_cosine_with_warmup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_max</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_warmup</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cosine_eta_min</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warmup_decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">LRScheduler</span></span></span><a class="reference internal" href="_modules/decent_dp/optim.html#lr_scheduler_fn_cosine_with_warmup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.optim.lr_scheduler_fn_cosine_with_warmup" title="Link to this definition"></a></dt>
<dd><p>An example of a function that creates a learning rate scheduler that combines a warmup and a cosine annealing schedule.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>a learning rate scheduler with the linear warmup followed by the cosine annealing</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>LRScheduler</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="decent_dp.optim.optim_fn_accum_adam">
<span class="sig-prename descclassname"><span class="pre">decent_dp.optim.</span></span><span class="sig-name descname"><span class="pre">optim_fn_accum_adam</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.999</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3.0517578125e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accum_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Optimizer</span></span></span><a class="reference internal" href="_modules/decent_dp/optim.html#optim_fn_accum_adam"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.optim.optim_fn_accum_adam" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>An example of a function that creates an AccumAdam optimizer with the given parameters and their names.</dt><dd><p>To change the hyperparameters of the optimizer, you can wrap it with <cite>functools.partial</cite> and pass the new values.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>an AccumAdam optimizer</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Optimizer</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="decent_dp.optim.optim_fn_accum_adamw">
<span class="sig-prename descclassname"><span class="pre">decent_dp.optim.</span></span><span class="sig-name descname"><span class="pre">optim_fn_accum_adamw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.999</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accum_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Optimizer</span></span></span><a class="reference internal" href="_modules/decent_dp/optim.html#optim_fn_accum_adamw"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.optim.optim_fn_accum_adamw" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>An example of a function that creates an AccumAdamW optimizer with the given parameters and their names.</dt><dd><p>To change the hyperparameters of the optimizer, you can wrap it with <cite>functools.partial</cite> and pass the new values.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>an AccumAdamW optimizer</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Optimizer</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="decent_dp.optim.optim_fn_adam">
<span class="sig-prename descclassname"><span class="pre">decent_dp.optim.</span></span><span class="sig-name descname"><span class="pre">optim_fn_adam</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.999</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3.0517578125e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Optimizer</span></span></span><a class="reference internal" href="_modules/decent_dp/optim.html#optim_fn_adam"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.optim.optim_fn_adam" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>An example of a function that creates an Adam optimizer with the given parameters and their names.</dt><dd><p>To change the hyperparameters of the optimizer, you can wrap it with <cite>functools.partial</cite> and pass the new values.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>an Adam optimizer</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Optimizer</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="decent_dp.optim.optim_fn_adamw">
<span class="sig-prename descclassname"><span class="pre">decent_dp.optim.</span></span><span class="sig-name descname"><span class="pre">optim_fn_adamw</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta2</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.999</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Optimizer</span></span></span><a class="reference internal" href="_modules/decent_dp/optim.html#optim_fn_adamw"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.optim.optim_fn_adamw" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>An example of a function that creates an AdamW optimizer with the given parameters and their names.</dt><dd><p>To change the hyperparameters of the optimizer, you can wrap it with <cite>functools.partial</cite> and pass the new values.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>an AdamW optimizer</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Optimizer</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-decent_dp.topo">
<span id="decent-dp-topo-module"></span><h2>decent_dp.topo module<a class="headerlink" href="#module-decent_dp.topo" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="decent_dp.topo.Edge">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">decent_dp.topo.</span></span><span class="sig-name descname"><span class="pre">Edge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ranks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ProcessGroup</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/decent_dp/topo.html#Edge"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.topo.Edge" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Edge class for defining communication patterns among workers.</p>
<p>Weight defines the fraction of the message that each worker keeps. For example, if the weight is 0.3,         then the worker keeps 30% of its message and shares 70% with other workers.         $x_i = x_i * weight + sum_{j in text{ranks}} x_j * (1 - weight) / text{len(ranks)}$.         The weight should be between 0 and 1 for convergence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ranks</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of ranks of workers that communicate in this edge</p></li>
<li><p><strong>weights</strong> (<em>List</em><em>[</em><em>float</em><em>]</em>) – List of weights for each worker in the edge (required to be the same length as ranks)</p></li>
<li><p><strong>group</strong> (<em>Optional</em><em>[</em><em>ProcessGroup</em><em>]</em>) – Process group for the edge, which will be created by Topology class</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="decent_dp.topo.Edge.group">
<span class="sig-name descname"><span class="pre">group</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ProcessGroup</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#decent_dp.topo.Edge.group" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="decent_dp.topo.Edge.ranks">
<span class="sig-name descname"><span class="pre">ranks</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#decent_dp.topo.Edge.ranks" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="decent_dp.topo.Edge.weight">
<span class="sig-name descname"><span class="pre">weight</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#decent_dp.topo.Edge.weight" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="decent_dp.topo.Topology">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">decent_dp.topo.</span></span><span class="sig-name descname"><span class="pre">Topology</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">local_world_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/decent_dp/topo.html#Topology"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.topo.Topology" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="decent_dp.topo.Topology.get_edge">
<span class="sig-name descname"><span class="pre">get_edge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#decent_dp.topo.Edge" title="decent_dp.topo.Edge"><span class="pre">Edge</span></a></span></span><a class="reference internal" href="_modules/decent_dp/topo.html#Topology.get_edge"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.topo.Topology.get_edge" title="Link to this definition"></a></dt>
<dd><p>Get the edge for the given iteration</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="decent_dp.topo.TopologyReg">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">decent_dp.topo.</span></span><span class="sig-name descname"><span class="pre">TopologyReg</span></span><a class="reference internal" href="_modules/decent_dp/topo.html#TopologyReg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.topo.TopologyReg" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="decent_dp.topo.TopologyReg.register">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">register</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Callable</span></span></span><a class="reference internal" href="_modules/decent_dp/topo.html#TopologyReg.register"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.topo.TopologyReg.register" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="decent_dp.topo.TopologyReg.registry">
<span class="sig-name descname"><span class="pre">registry</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#decent_dp.topo.Topology" title="decent_dp.topo.Topology"><span class="pre">Topology</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{'alternating-exp-ring':</span> <span class="pre">&lt;class</span> <span class="pre">'decent_dp.topo.AlternatingExpRingTopology'&gt;,</span> <span class="pre">'complete':</span> <span class="pre">&lt;class</span> <span class="pre">'decent_dp.topo.CompleteTopology'&gt;,</span> <span class="pre">'one-peer-exp':</span> <span class="pre">&lt;class</span> <span class="pre">'decent_dp.topo.OnePeerExpTopology'&gt;,</span> <span class="pre">'ring':</span> <span class="pre">&lt;class</span> <span class="pre">'decent_dp.topo.RingTopology'&gt;}</span></em><a class="headerlink" href="#decent_dp.topo.TopologyReg.registry" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-decent_dp.utils">
<span id="decent-dp-utils-module"></span><h2>decent_dp.utils module<a class="headerlink" href="#module-decent_dp.utils" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="decent_dp.utils.initialize_dist">
<span class="sig-prename descclassname"><span class="pre">decent_dp.utils.</span></span><span class="sig-name descname"><span class="pre">initialize_dist</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/decent_dp/utils.html#initialize_dist"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#decent_dp.utils.initialize_dist" title="Link to this definition"></a></dt>
<dd><p>A utility function to initialize the distributed environment</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>rank and world size</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple[int, int]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-decent_dp">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-decent_dp" title="Link to this heading"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="modules.html" class="btn btn-neutral float-left" title="decent_dp" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="schema.html" class="btn btn-neutral float-right" title="Algorithm schemas" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Zesen Wang.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>