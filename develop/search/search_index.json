{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Decent-DP Documentation","text":"<p>Decent-DP stands for decentralized data parallelism. It is a cutting-edge PyTorch extension designed to simplify and accelerate decentralized data parallel training.</p> <p>As the official implementation of the paper [ICLR'25] From Promise to Practice: Realizing High-performance Decentralized Training, Decent-DP empowers you to scale multi-worker training efficiently\u2014eliminating centralized bottlenecks and streamlining your deep learning pipelines.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Decentralized Architecture: Efficiently distributes training across multiple workers without relying on a central coordinator.</li> <li>Seamless PyTorch Integration: Easily plug into your existing PyTorch codebase with minimal modifications.</li> <li>High-Performance: Optimized for speed and scalability based on state-of-the-art research.</li> <li>Flexible and Extensible: Supports various algorithmic schemas to suit different training scenarios and model architectures.</li> </ul>"},{"location":"#installation","title":"Installation","text":""},{"location":"#via-pip-recommended","title":"Via pip (Recommended)","text":"<p>Install Decent-DP directly from PyPI:</p> <pre><code>pip install decent-dp\n</code></pre>"},{"location":"#via-uv","title":"Via uv","text":"<p>If you're using uv as your package manager:</p> <pre><code>uv add decent-dp\n</code></pre>"},{"location":"#from-source","title":"From Source","text":"<p>To install from source, clone the repository and install in editable mode:</p> <pre><code>git clone https://github.com/WangZesen/Decent-DP.git\ncd Decent-DP\npip install -e .\n</code></pre>"},{"location":"#quickstart-example","title":"Quickstart Example","text":"<p>Here is a complete example of how to use Decent-DP to train a model:</p> <pre><code>import torch\nimport torch.nn as nn\nimport torch.distributed as dist\nfrom decent_dp.ddp import DecentralizedDataParallel as DecentDP\nfrom decent_dp.optim import optim_fn_adamw\nfrom decent_dp.utils import initialize_dist\n\n# Initialize distributed environment\nrank, world_size = initialize_dist()\n\n# Create your model\nmodel = nn.Sequential(\n    nn.Linear(10, 50),\n    nn.ReLU(),\n    nn.Linear(50, 1)\n).cuda()\n\n# Wrap model with DecentDP\nmodel = DecentDP(\n    model,\n    optim_fn=optim_fn_adamw,  # or your custom optimizer function\n    topology=\"complete\"      # or \"ring\", \"one-peer-exp\", \"alternating-exp-ring\"\n)\n\n# Training loop\nfor epoch in range(num_epochs):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.cuda(), target.cuda()\n        output = model(data)\n        loss = nn.functional.mse_loss(output, target)\n\n        # Zero gradients, backward pass\n        model.zero_grad()\n        loss.backward()\n        # Note: optimizer.step() is automatically called by DecentDP\n\n    # Evaluation\n    model.eval()\n    with torch.no_grad():\n        for data, target in val_loader:\n            data, target = data.cuda(), target.cuda()\n            output = model(data)\n            val_loss = nn.functional.mse_loss(output, target)\n</code></pre> <p>Launch the script on multiple processes/nodes using <code>torchrun</code>:</p> <pre><code>torchrun --nproc_per_node=4 your_training_script.py\n</code></pre>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<p>To help you get the most out of Decent-DP, we've organized our documentation into the following sections:</p> <ol> <li>Getting Started - Installation and basic usage</li> <li>Tutorials:<ul> <li>Decentralized Data Parallel - Detailed guide on using the core DDP implementation</li> <li>Topology Design - Understanding different communication topologies</li> <li>Custom Optimizers - Creating optimizer functions compatible with Decent-DP</li> </ul> </li> <li>Benchmarks - Performance comparisons and hardware requirements</li> <li>API Reference - Detailed API documentation for all modules</li> </ol>"},{"location":"#citation","title":"Citation","text":"<p>If you find this repository helpful, please consider citing the following paper:</p> <pre><code>@inproceedings{wang2025promise,\n    title={From Promise to Practice: Realizing High-performance Decentralized Training},\n    author={Zesen Wang, Jiaojiao Zhang, Xuyang Wu, and Mikael Johansson},\n    booktitle={International Conference on Learning Representations},\n    year={2025},\n    url={https://openreview.net/forum?id=lo3nlFHOft},\n}\n</code></pre>"},{"location":"api/","title":"API Reference","text":"<p>This document provides detailed API references for all modules in Decent-DP.</p>"},{"location":"api/#decent_dpddp","title":"decent_dp.ddp","text":"<p>The core module containing the <code>DecentralizedDataParallel</code> class, which is the main wrapper for enabling decentralized training on PyTorch models.</p>"},{"location":"api/#decent_dp.ddp","title":"<code>decent_dp.ddp</code>","text":""},{"location":"api/#decent_dp.ddp.OPTIM_FN_TYPE","title":"<code>OPTIM_FN_TYPE = Callable[[List[Tuple[str, Tensor]]], Optimizer]</code>  <code>module-attribute</code>","text":"<p>Data type for the optimizer function</p>"},{"location":"api/#decent_dp.ddp.LR_SCHEDULER_FN_TYPE","title":"<code>LR_SCHEDULER_FN_TYPE = Callable[[Optimizer], LRScheduler]</code>  <code>module-attribute</code>","text":"<p>Data type for the learning rate scheduler function</p>"},{"location":"api/#decent_dp.ddp.DecentralizedDataParallel","title":"<code>DecentralizedDataParallel</code>","text":"<p>               Bases: <code>Module</code></p> <p>Decentralized data parallel wrapper for PyTorch module</p> <ol> <li>The wrapper places hooks during the backward pass to trace the order of used parameters in the first iteration, and     2. Split the parameters into buckets and create optimizers and LR schedulers for each bucket,         Add hooks on the last parameter of each bucket to perform the bucket-wise update and communication,     3. During the backward passes in the training loop, the hooks are triggered to perform the bucket-wise update and communication</li> </ol> Note <p>The wrapper currently does not support \"channels_last\" memory format.</p> Note <p>The wrapper assumes that the parameter will only be used once in the backward pass</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>PyTorch module to be wrapped</p> required <code>optim_fn</code> <code>OPTIM_FN_TYPE</code> <p>Function to create the optimizer, which takes a list of tuples of parameters and their names</p> required <code>lr_scheduler_fn</code> <code>Optional[LR_SCHEDULER_FN_TYPE]</code> <p>Function to create the learning rate scheduler,             which takes the optimizer as input. Defaults to None.</p> <code>None</code> <code>topology</code> <code>str</code> <p>Topology of the decentralized communication graph. Defaults to 'complete'.</p> <code>'complete'</code> <code>scaler</code> <code>Optional[GradScaler]</code> <p>Gradient scaler for mixed precision training. Defaults to None.</p> <code>None</code> <code>grad_clip_norm</code> <code>float</code> <p>Gradient clipping norm, set to 0.0 if no gradient clipping is applied. Defaults to 0.0.</p> <code>0.0</code> <code>param_as_bucket_view</code> <code>bool</code> <p>Whether to use the parameter as a view of part of the contiguous buffer. Defaults to True.</p> <code>True</code> <code>sync_buffer_in_global_avg</code> <code>bool</code> <p>Whether to synchronize the float buffers in the global average. Defaults to False.</p> <code>False</code> <code>bucket_size_in_mb</code> <code>int</code> <p>Size of the bucket in MB. Defaults to 25 MB.</p> <code>25</code> <code>_local_world_size</code> <code>Optional[int]</code> <p>Provide the local world size and not using the environment variable. Defaults to None.</p> <code>None</code> Source code in <code>src/decent_dp/ddp.py</code> <pre><code>class DecentralizedDataParallel(Module):\n    \"\"\"Decentralized data parallel wrapper for PyTorch module\n\n    1. The wrapper places hooks during the backward pass to trace the order of used parameters in the first iteration, and \\\n    2. Split the parameters into buckets and create optimizers and LR schedulers for each bucket, \\\n        Add hooks on the last parameter of each bucket to perform the bucket-wise update and communication, \\\n    3. During the backward passes in the training loop, the hooks are triggered to perform the bucket-wise update and communication\n\n    Note:\n        The wrapper currently does not support \"channels_last\" memory format.\n\n    Note:\n        The wrapper assumes that the parameter will only be used once in the backward pass\n\n    Args:\n        model (Module): PyTorch module to be wrapped\n        optim_fn (OPTIM_FN_TYPE): Function to create the optimizer, which takes a list of tuples of parameters and their names\n        lr_scheduler_fn (Optional[LR_SCHEDULER_FN_TYPE], optional): Function to create the learning rate scheduler, \\\n            which takes the optimizer as input. Defaults to None.\n        topology (str, optional): Topology of the decentralized communication graph. Defaults to 'complete'.\n        scaler (Optional[GradScaler], optional): Gradient scaler for mixed precision training. Defaults to None.\n        grad_clip_norm (float, optional): Gradient clipping norm, set to 0.0 if no gradient clipping is applied. Defaults to 0.0.\n        param_as_bucket_view (bool, optional): Whether to use the parameter as a view of part of the contiguous buffer. Defaults to True.\n        sync_buffer_in_global_avg (bool, optional): Whether to synchronize the float buffers in the global average. Defaults to False.\n        bucket_size_in_mb (int, optional): Size of the bucket in MB. Defaults to 25 MB.\n        _local_world_size (Optional[int], optional): Provide the local world size and not using the environment variable. Defaults to None.\n    \"\"\"\n\n    \"\"\"Buffer data types that need to be synchronized in global average\"\"\"\n    FLOAT_DTYPES = [torch.float16, torch.float32, torch.float64]\n\n    def __init__(\n        self,\n        model: Module,\n        optim_fn: OPTIM_FN_TYPE,\n        lr_scheduler_fn: Optional[LR_SCHEDULER_FN_TYPE] = None,\n        topology: str = \"complete\",\n        scaler: Optional[GradScaler] = None,\n        grad_clip_norm: float = 0.0,\n        param_as_bucket_view: bool = True,\n        sync_buffer_in_global_avg: bool = False,\n        bucket_size_in_mb: int = 25,\n        _local_world_size: Optional[int] = None,\n    ):\n        super(DecentralizedDataParallel, self).__init__()\n        assert dist.is_available() and dist.is_initialized(), \"Distributed environment is not initialized\"\n\n        self._model = model.cuda() if torch.cuda.is_available() else model\n        self._optim_fn = optim_fn\n        self._lr_schd_fn = lr_scheduler_fn\n        self._scaler = scaler\n        self._grad_clip_norm = grad_clip_norm\n        self._param_as_bucket_view = param_as_bucket_view\n        self._sync_buffer_in_global_avg = sync_buffer_in_global_avg\n        self._bucket_size = bucket_size_in_mb * 1024 * 1024\n        self._local_world_size = (\n            _local_world_size if _local_world_size is not None else int(os.environ.get(\"LOCAL_WORLD_SIZE\", 1))\n        )\n\n        # get the rank and world size\n        self._rank = dist.get_rank()\n        self._world_size = dist.get_world_size()\n\n        # check if the model is with \"channels_last\" memory format\n        if self._check_channels_last():\n            if self._rank == 0:\n                logger.debug('The model is with \"channels_last\" memory format')\n\n        if self._rank == 0:\n            logger.debug(\"Initializing Decentralized Data Parallel\")\n            logger.debug(\n                f\"Rank: {self._rank}, Local World Size: {self._local_world_size}, World Size: {self._world_size}, Topology: {topology}\"\n            )\n\n        # model parameters\n        self._params: List[Tensor] = list([x for _, x in self._model.named_parameters() if x.requires_grad])\n        self._param_names: List[str] = list([n for n, x in self._model.named_parameters() if x.requires_grad])\n\n        # trace hooks and traced parameter ids\n        self._trace_hooks: List[RemovableHandle] = []\n        self._traced_param_ids: List[int] = []\n\n        self._step: int = 0\n        self._comm_ops: List[Optional[Work]] = []\n\n        self._ddp_hooks: List[RemovableHandle] = []\n        self._param_buckets: List[List[Tensor]] = []\n        self._param_blocks: List[Tensor] = []\n        self._comm_buffers: List[List[Tensor]] = []\n        self._comm_blocks: List[Tensor] = []\n        self._param_backups: List[Tensor] = []\n\n        # Optimizer and LR scheduler\n        self._optims: List[Optimizer] = []\n        self._lr_schedulers: List[Optional[LRScheduler]] = []\n\n        # initialize the topology\n        self._topo: Topology = TopologyReg.registry[topology](self._local_world_size)\n\n        # create hooks to trace the used parameters in backward\n        self._create_trace_hooks()\n\n        # sync the parameters at the start\n        self._sync_at_start()\n\n        # flag for gradient accumulation\n        self._is_grad_accum_enable: bool = False\n\n        # flag for initializing the parameters\n        self._initialized: bool = False\n\n        # adaptive factor\n        self._adaptive_factor: float = 1.0\n\n    def _check_channels_last(self) -&gt; bool:\n        \"\"\"Check if the model is with \"channels_last\" memory format\n\n        Returns:\n            bool: True if the model is with \"channels_last\" memory format\n        \"\"\"\n        if any(\n            [\n                x.is_contiguous(memory_format=torch.channels_last) and (not x.is_contiguous())\n                for x in self._model.parameters()\n                if len(x.shape) == 4\n            ]\n        ):\n            return True\n        return False\n\n    def _create_trace_hooks(self):\n        \"\"\"Create hooks to trace the order of used parameters in backward pass\"\"\"\n        for pid, param in enumerate(self._params):\n            self._trace_hooks.append(\n                param.register_post_accumulate_grad_hook(partial(lambda data, pid: self._trace_fn(data, pid), pid=pid))\n            )\n\n    @torch.no_grad()\n    def _sync_at_start(self):\n        \"\"\"Broadcast the parameters of worker 0 to all other workers at the start\"\"\"\n        for param in self._params:\n            dist.broadcast(param, 0)\n\n    def set_accumulate_grad(self, enable: bool = True):\n        \"\"\"Set the gradient accumulation mode\n\n        Args:\n            enable (bool, optional): Whether to accumulate the gradients. Defaults to True.\n        \"\"\"\n        self._is_grad_accum_enable = enable\n\n    \"\"\"Hook functions\"\"\"\n\n    @torch.no_grad()\n    def _trace_fn(self, _: Tensor, pid: int):\n        \"\"\"Hook function to trace the order of used parameters in backward pass\n\n        Args:\n            _ (Tensor): corresponding tensor (not used)\n            pid (int): parameter id\n\n        Raises:\n            AssertionError: The parameter is used more than once in the backward pass\n        \"\"\"\n        if self._is_grad_accum_enable:\n            return\n        assert pid not in self._traced_param_ids, \"The parameter is used more than once in the backward pass\"\n        self._traced_param_ids.append(pid)\n\n    @torch.no_grad()\n    def _ddp_fn(self, _: Tensor, bucket_id: int):\n        \"\"\"Hook function to perform the bucket-wise update and communication\n\n        Args:\n            _ (Tensor): corresponding tensor (not used)\n            bucket_id (int): bucket id\n        \"\"\"\n\n        # skip the update and communication if the model is accumulating gradients\n        if self._is_grad_accum_enable:\n            return\n\n        # perform the bucket-wise update and communication when all gradients in the bucket are accumulated\n        comm_op = self._comm_ops[bucket_id]\n        if comm_op is not None:\n            # wait for the communication from the last iteration\n            comm_op.wait()\n            self._comm_ops[bucket_id] = None\n\n            # get the peers to communicate with in this iteration\n            edge = self._topo.get_edge(self._step)\n            weight = edge.weight\n\n            # optionally call the pre_average_hook for optimizers using the communication information\n            if hasattr(self._optims[bucket_id], \"pre_average_hook\"):\n                self._optims[bucket_id].pre_average_hook(edge, weight)  # type: ignore\n\n            # replace the local model with the mixed model\n            if self._param_as_bucket_view:\n                self._param_blocks[bucket_id].mul_(\n                    (1 - self._adaptive_factor)\n                    + self._adaptive_factor * (weight - (1 - weight) / (len(edge.ranks) - 1))\n                )\n                self._param_blocks[bucket_id].add_(self._comm_blocks[bucket_id], alpha=self._adaptive_factor)\n            else:\n                torch._foreach_mul_(\n                    self._param_buckets[bucket_id],\n                    (1 - self._adaptive_factor)\n                    + self._adaptive_factor * (weight - (1 - weight) / (len(edge.ranks) - 1)),\n                )\n                torch._foreach_add_(\n                    self._param_buckets[bucket_id], self._comm_buffers[bucket_id], alpha=self._adaptive_factor\n                )\n\n        # perform local update\n        if self._scaler:\n            if self._grad_clip_norm &gt; 0:\n                self._scaler.unscale_(self._optims[bucket_id])\n                torch.nn.utils.clip_grad_norm_(self._param_buckets[bucket_id], self._grad_clip_norm)\n            self._scaler.step(self._optims[bucket_id])\n            if bucket_id == len(self._param_buckets) - 1:\n                self._scaler.update()\n        else:\n            if self._grad_clip_norm &gt; 0:\n                torch.nn.utils.clip_grad_norm_(self._param_buckets[bucket_id], self._grad_clip_norm)\n            self._optims[bucket_id].step()\n        self._optims[bucket_id].zero_grad()\n\n        if self._lr_schedulers[bucket_id] is not None:\n            scheduler = cast(LRScheduler, self._lr_schedulers[bucket_id])\n            scheduler.step()\n\n        # launch the next communication after updating the weights\n        if self._param_as_bucket_view:\n            self._comm_blocks[bucket_id].copy_(self._param_blocks[bucket_id])\n        else:\n            torch._foreach_copy_(self._comm_buffers[bucket_id], self._param_buckets[bucket_id])\n\n        edge = self._topo.get_edge(self._step + 1)\n        weight = edge.weight\n        self._comm_blocks[bucket_id].mul_((1 - weight) / (len(edge.ranks) - 1))\n\n        self._comm_ops[bucket_id] = dist.all_reduce(\n            self._comm_blocks[bucket_id], op=dist.ReduceOp.SUM, group=edge.group, async_op=True\n        )\n\n    @torch.no_grad()\n    def _initialize_params(self):\n        \"\"\"Initialize the parameter buckets and communication buffers\n\n        Raises:\n            RuntimeError: Number/Order of elements in used parameters is different on different nodes\n        \"\"\"\n\n        # verify the number of elements and the order of the parameters on different nodes are the same\n        verify = [[(i, self._params[i].numel()) for i in self._traced_param_ids]]\n        result = [[(0, 0)]] if self._rank != 0 else verify\n        dist.broadcast_object_list(result, src=0)\n        if not all([x == y for x, y in zip(verify[0], result[0])]):\n            raise RuntimeError(\"Number/Order of elements in used parameters is different on different nodes\")\n\n        # remove the trace hooks\n        for hook in self._trace_hooks:\n            hook.remove()\n        del self._trace_hooks\n\n        # split the parameters into roughly equal-size buckets, and register hooks on the last parameter of each bucket\n        start = 0\n        size = 0\n        for i in range(len(self._traced_param_ids)):\n            size += (\n                self._align(self._params[self._traced_param_ids[i]].numel())\n                * self._params[self._traced_param_ids[i]].element_size()\n            )\n            if (size &gt;= self._bucket_size) or (i == len(self._traced_param_ids) - 1):\n                # register hooks on the last parameter of each bucket, passing the bucket id\n                self._ddp_hooks.append(\n                    self._params[self._traced_param_ids[i]].register_post_accumulate_grad_hook(\n                        partial(lambda data, bucket_id: self._ddp_fn(data, bucket_id), bucket_id=len(self._ddp_hooks))\n                    )\n                )\n                self._param_buckets.append([self._params[j] for j in self._traced_param_ids[start : i + 1]])\n                param_names = [self._param_names[j] for j in self._traced_param_ids[start : i + 1]]\n\n                # create optimizer and learning rate scheduler for parameters in each bucket\n                self._optims.append(self._optim_fn(list(zip(param_names, self._param_buckets[-1]))))\n                self._lr_schedulers.append(self._lr_schd_fn(self._optims[-1]) if self._lr_schd_fn is not None else None)\n                size = 0\n                start = i + 1\n\n        size_dict = {}\n\n        for i in range(len(self._param_buckets)):\n            total_size = sum([self._align(p.numel()) for p in self._param_buckets[i]])\n\n            # make sure the total size is unique for each bucket \\\n            # (not necessary, but make sure the communication operations are unique for each bucket with negligible overhead)\n            while total_size in size_dict:\n                total_size += 32\n            size_dict[total_size] = True\n\n            # create the communication buffer for each bucket\n            comm_block = torch.zeros(\n                total_size,\n                device=self._param_buckets[i][0].device,\n                requires_grad=False,\n                dtype=self._param_buckets[i][0].dtype,\n            )\n\n            if self._param_as_bucket_view:\n                # create contiguous blocks for each bucket, and let the parameters be views of the fragments of the block\n                self._param_blocks.append(\n                    torch.zeros(\n                        total_size,\n                        device=self._param_buckets[i][0].device,\n                        requires_grad=True,\n                        dtype=self._param_buckets[i][0].dtype,\n                    )\n                )\n                start = 0\n                for j in range(len(self._param_buckets[i])):\n                    size = self._param_buckets[i][j].numel()\n                    if (\n                        (len(self._param_buckets[i][j].shape) == 4)\n                        and self._param_buckets[i][j].is_contiguous(memory_format=torch.channels_last)\n                        and (not self._param_buckets[i][j].is_contiguous())\n                    ):\n                        # permute the tensor to the channels_last format\n                        self._param_blocks[-1].narrow(0, start, size).copy_(\n                            self._param_buckets[i][j].permute(0, 2, 3, 1).view(-1)\n                        )\n                        self._param_buckets[i][j].data = (\n                            self._param_blocks[-1]\n                            .narrow(0, start, size)\n                            .view(\n                                (\n                                    self._param_buckets[i][j].shape[0],\n                                    self._param_buckets[i][j].shape[2],\n                                    self._param_buckets[i][j].shape[3],\n                                    self._param_buckets[i][j].shape[1],\n                                )\n                            )\n                            .permute(0, 3, 1, 2)\n                        )\n                        assert self._param_buckets[i][j].is_contiguous(memory_format=torch.channels_last)\n                        assert not self._param_buckets[i][j].is_contiguous()\n                    else:\n                        # otherwise, copy the tensor directly\n                        assert self._param_buckets[i][j].is_contiguous()\n                        self._param_blocks[-1].narrow(0, start, size).copy_(self._param_buckets[i][j].view(-1))\n                        self._param_buckets[i][j].data = (\n                            self._param_blocks[-1].narrow(0, start, size).view_as(self._param_buckets[i][j])\n                        )\n                    start += self._align(size)\n\n            self._comm_blocks.append(comm_block)\n            start = 0\n            self._comm_buffers.append([])\n            for j in range(len(self._param_buckets[i])):\n                size = self._param_buckets[i][j].numel()\n                if (\n                    (len(self._param_buckets[i][j].shape) == 4)\n                    and self._param_buckets[i][j].is_contiguous(memory_format=torch.channels_last)\n                    and (not self._param_buckets[i][j].is_contiguous())\n                ):\n                    # permute the tensor to the channels_last format\n                    self._comm_buffers[-1].append(\n                        comm_block.narrow(0, start, size)\n                        .view(\n                            (\n                                self._param_buckets[i][j].shape[0],\n                                self._param_buckets[i][j].shape[2],\n                                self._param_buckets[i][j].shape[3],\n                                self._param_buckets[i][j].shape[1],\n                            )\n                        )\n                        .permute(0, 3, 1, 2)\n                    )\n                else:\n                    self._comm_buffers[-1].append(comm_block.narrow(0, start, size).view_as(self._param_buckets[i][j]))\n                start += self._align(size)\n\n                # attach the communication buffer to the parameter for \"pre_average_hook\" in the optimizer\n                if hasattr(self._optims[i], \"pre_average_hook\"):\n                    setattr(self._param_buckets[i][j], \"comm_buffer\", self._comm_buffers[-1][-1])\n\n            # initialize the communication buffer with the initial parameters\n            torch._foreach_copy_(self._comm_buffers[-1], self._param_buckets[i])\n\n        self._comm_ops = [None] * len(self._param_buckets)\n\n    def _align(self, size: int):\n        \"\"\"Align the size to 128-byte boundary\"\"\"\n        return math.ceil(size / 32) * 32\n\n    \"\"\"Delegation functions\"\"\"\n\n    def train(self, mode: bool = True):\n        \"\"\"Set the module in training mode\n\n        Args:\n            mode (bool, optional): Whether to set the module in training mode. Defaults to True.\n        \"\"\"\n        self._model.train(mode)\n        return self\n\n    def eval(self):\n        \"\"\"Set the module in evaluation mode\"\"\"\n        self._model.eval()\n        return self\n\n    def forward(self, *args, **kwargs):\n        \"\"\"Forward pass of the model\"\"\"\n        # lazy initialization at the second iteration\n        if (self._step == 1) and (not self._initialized):\n            self._initialized = True\n            # initialize the parameters and communication buffers\n            self._initialize_params()\n\n            # manually trigger the communications for the first iteration only\n            with torch.no_grad():\n                edge = self._topo.get_edge(self._step)\n                weight = edge.weight\n                for i in range(len(self._param_buckets)):\n                    # optionally call the pre_average_hook for optimizers using the communication information\n                    if hasattr(self._optims[i], \"pre_average_hook\"):\n                        self._optims[i].pre_average_hook(edge, weight)  # type: ignore\n\n                    # update parameters and launch the first communication\n                    if self._scaler:\n                        if self._grad_clip_norm &gt; 0:\n                            self._scaler.unscale_(self._optims[i])\n                            torch.nn.utils.clip_grad_norm_(self._param_buckets[i], self._grad_clip_norm)\n                        self._scaler.step(self._optims[i])\n                        if i == len(self._param_buckets) - 1:\n                            self._scaler.update()\n                            # TODO: synchronize the scaler state across all workers?\n                    else:\n                        if self._grad_clip_norm &gt; 0:\n                            torch.nn.utils.clip_grad_norm_(self._param_buckets[i], self._grad_clip_norm)\n                        self._optims[i].step()\n                    self._optims[i].zero_grad()\n                    if self._lr_schedulers[i] is not None:\n                        scheduler = cast(LRScheduler, self._lr_schedulers[i])\n                        scheduler.step()\n\n                    # launch the first communication\n                    if self._param_as_bucket_view:\n                        self._comm_blocks[i].copy_(self._param_blocks[i])\n                    else:\n                        torch._foreach_copy_(self._comm_buffers[i], self._param_buckets[i])\n\n                    self._comm_blocks[i].mul_((1 - weight) / (len(edge.ranks) - 1))\n                    comm_op = dist.all_reduce(\n                        self._comm_blocks[i], op=dist.ReduceOp.SUM, group=edge.group, async_op=True\n                    )\n                    self._comm_ops[i] = comm_op\n                    # wait for the communication to finish to fully synchronize the workers\n                    assert comm_op is not None\n                    comm_op.wait()\n\n        if self._model.training and (not self._is_grad_accum_enable):\n            self._step += 1\n\n        with torch.autograd.profiler.record_function(\"DecentralizedDataParallel.forward\"):\n            output = self._model(*args, **kwargs)\n            return output\n\n    def parameters(self, recurse: bool = True) -&gt; Iterator[Parameter]:\n        \"\"\"Get the parameters of the model\n\n        Args:\n            recurse (bool, optional): Whether to get the parameters recursively. Defaults to True.\n\n        Yields:\n            Iterator[Parameter]: The iterator of the parameters\n        \"\"\"\n        yield from self._model.parameters(recurse)\n\n    def named_parameters(\n        self, prefix: str = \"\", recurse: bool = True, remove_duplicate: bool = True\n    ) -&gt; Iterator[Tuple[str, Parameter]]:\n        \"\"\"Get the named parameters of the model\"\"\"\n        return super().named_parameters(prefix, recurse, remove_duplicate)\n\n    \"\"\"Utility functions\"\"\"\n\n    @torch.no_grad()\n    def global_avg(self, will_revert: bool = True, return_d2c: bool = False) -&gt; Optional[float]:\n        \"\"\"Perform global average of the model parameters across all workers\n\n        Args:\n            will_revert (bool, optional): Whether to backup the parameters for reverting. Defaults to True.\n            return_d2c (bool, optional): Whether to return the distance to center. Defaults to False.\n        \"\"\"\n        for op in self._comm_ops:\n            if op is not None:\n                op.wait()\n        if not will_revert:\n            self._comm_ops = [None for _ in range(len(self._param_buckets))]\n\n        if will_revert or return_d2c:\n            if len(self._param_backups) == 0:\n                for i in range(len(self._params)):\n                    self._param_backups.append(self._params[i].data.detach().clone())\n            else:\n                torch._foreach_copy_(self._param_backups, [x.data for x in self._params])\n\n        if self._param_as_bucket_view:\n            torch._foreach_div_(self._param_blocks, self._world_size)\n            for i in range(len(self._param_blocks)):\n                dist.all_reduce(self._param_blocks[i], op=dist.ReduceOp.SUM)\n        else:\n            torch._foreach_div_([x.data for x in self._params], self._world_size)\n            for x in self._params:\n                dist.all_reduce(x.data, op=dist.ReduceOp.SUM)\n\n        if self._sync_buffer_in_global_avg:\n            # globally average the float buffers (e.g. running mean and variance in batch normalization)\n            for x in self._model.buffers():\n                if x.dtype in self.FLOAT_DTYPES:\n                    dist.all_reduce(x.data, op=dist.ReduceOp.SUM)\n                    x.data.div_(self._world_size)\n\n        if return_d2c:\n            return torch.norm(\n                torch.stack(\n                    torch._foreach_norm(torch._foreach_sub([x.data for x in self._params], self._param_backups))\n                )\n            ).item()\n\n    @torch.no_grad()\n    def revert_global_avg(self):\n        \"\"\"Revert the parameters to the state before global average\"\"\"\n        if len(self._param_backups) == 0:\n            raise RuntimeError(\"No backup found for reverting global average\")\n        torch._foreach_copy_([x.data for x in self._params], self._param_backups)\n\n    @torch.no_grad()\n    def get_lr(self) -&gt; float:\n        \"\"\"\n        Get the current learning rate from the first learning rate scheduler\n\n        Returns:\n            float: Current learning rate\n        \"\"\"\n        if self._initialized:\n            scheduler = self._lr_schedulers[0]\n            assert scheduler is not None, \"No learning rate scheduler is defined\"\n            return scheduler.get_last_lr()[0]\n        else:\n            return 0.0\n\n    @torch.no_grad()\n    def set_adaptive_factor(self, factor: float):\n        \"\"\"Set the adaptive factor for scaling the model parameters during communication\n\n        Args:\n            factor (float): Adaptive factor\n        \"\"\"\n        self._adaptive_factor = factor\n</code></pre>"},{"location":"api/#decent_dp.ddp.DecentralizedDataParallel.set_accumulate_grad","title":"<code>set_accumulate_grad(enable=True)</code>","text":"<p>Set the gradient accumulation mode</p> <p>Parameters:</p> Name Type Description Default <code>enable</code> <code>bool</code> <p>Whether to accumulate the gradients. Defaults to True.</p> <code>True</code> Source code in <code>src/decent_dp/ddp.py</code> <pre><code>def set_accumulate_grad(self, enable: bool = True):\n    \"\"\"Set the gradient accumulation mode\n\n    Args:\n        enable (bool, optional): Whether to accumulate the gradients. Defaults to True.\n    \"\"\"\n    self._is_grad_accum_enable = enable\n</code></pre>"},{"location":"api/#decent_dp.ddp.DecentralizedDataParallel.train","title":"<code>train(mode=True)</code>","text":"<p>Set the module in training mode</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>bool</code> <p>Whether to set the module in training mode. Defaults to True.</p> <code>True</code> Source code in <code>src/decent_dp/ddp.py</code> <pre><code>def train(self, mode: bool = True):\n    \"\"\"Set the module in training mode\n\n    Args:\n        mode (bool, optional): Whether to set the module in training mode. Defaults to True.\n    \"\"\"\n    self._model.train(mode)\n    return self\n</code></pre>"},{"location":"api/#decent_dp.ddp.DecentralizedDataParallel.eval","title":"<code>eval()</code>","text":"<p>Set the module in evaluation mode</p> Source code in <code>src/decent_dp/ddp.py</code> <pre><code>def eval(self):\n    \"\"\"Set the module in evaluation mode\"\"\"\n    self._model.eval()\n    return self\n</code></pre>"},{"location":"api/#decent_dp.ddp.DecentralizedDataParallel.forward","title":"<code>forward(*args, **kwargs)</code>","text":"<p>Forward pass of the model</p> Source code in <code>src/decent_dp/ddp.py</code> <pre><code>def forward(self, *args, **kwargs):\n    \"\"\"Forward pass of the model\"\"\"\n    # lazy initialization at the second iteration\n    if (self._step == 1) and (not self._initialized):\n        self._initialized = True\n        # initialize the parameters and communication buffers\n        self._initialize_params()\n\n        # manually trigger the communications for the first iteration only\n        with torch.no_grad():\n            edge = self._topo.get_edge(self._step)\n            weight = edge.weight\n            for i in range(len(self._param_buckets)):\n                # optionally call the pre_average_hook for optimizers using the communication information\n                if hasattr(self._optims[i], \"pre_average_hook\"):\n                    self._optims[i].pre_average_hook(edge, weight)  # type: ignore\n\n                # update parameters and launch the first communication\n                if self._scaler:\n                    if self._grad_clip_norm &gt; 0:\n                        self._scaler.unscale_(self._optims[i])\n                        torch.nn.utils.clip_grad_norm_(self._param_buckets[i], self._grad_clip_norm)\n                    self._scaler.step(self._optims[i])\n                    if i == len(self._param_buckets) - 1:\n                        self._scaler.update()\n                        # TODO: synchronize the scaler state across all workers?\n                else:\n                    if self._grad_clip_norm &gt; 0:\n                        torch.nn.utils.clip_grad_norm_(self._param_buckets[i], self._grad_clip_norm)\n                    self._optims[i].step()\n                self._optims[i].zero_grad()\n                if self._lr_schedulers[i] is not None:\n                    scheduler = cast(LRScheduler, self._lr_schedulers[i])\n                    scheduler.step()\n\n                # launch the first communication\n                if self._param_as_bucket_view:\n                    self._comm_blocks[i].copy_(self._param_blocks[i])\n                else:\n                    torch._foreach_copy_(self._comm_buffers[i], self._param_buckets[i])\n\n                self._comm_blocks[i].mul_((1 - weight) / (len(edge.ranks) - 1))\n                comm_op = dist.all_reduce(\n                    self._comm_blocks[i], op=dist.ReduceOp.SUM, group=edge.group, async_op=True\n                )\n                self._comm_ops[i] = comm_op\n                # wait for the communication to finish to fully synchronize the workers\n                assert comm_op is not None\n                comm_op.wait()\n\n    if self._model.training and (not self._is_grad_accum_enable):\n        self._step += 1\n\n    with torch.autograd.profiler.record_function(\"DecentralizedDataParallel.forward\"):\n        output = self._model(*args, **kwargs)\n        return output\n</code></pre>"},{"location":"api/#decent_dp.ddp.DecentralizedDataParallel.parameters","title":"<code>parameters(recurse=True)</code>","text":"<p>Get the parameters of the model</p> <p>Parameters:</p> Name Type Description Default <code>recurse</code> <code>bool</code> <p>Whether to get the parameters recursively. Defaults to True.</p> <code>True</code> <p>Yields:</p> Type Description <code>Parameter</code> <p>Iterator[Parameter]: The iterator of the parameters</p> Source code in <code>src/decent_dp/ddp.py</code> <pre><code>def parameters(self, recurse: bool = True) -&gt; Iterator[Parameter]:\n    \"\"\"Get the parameters of the model\n\n    Args:\n        recurse (bool, optional): Whether to get the parameters recursively. Defaults to True.\n\n    Yields:\n        Iterator[Parameter]: The iterator of the parameters\n    \"\"\"\n    yield from self._model.parameters(recurse)\n</code></pre>"},{"location":"api/#decent_dp.ddp.DecentralizedDataParallel.named_parameters","title":"<code>named_parameters(prefix='', recurse=True, remove_duplicate=True)</code>","text":"<p>Get the named parameters of the model</p> Source code in <code>src/decent_dp/ddp.py</code> <pre><code>def named_parameters(\n    self, prefix: str = \"\", recurse: bool = True, remove_duplicate: bool = True\n) -&gt; Iterator[Tuple[str, Parameter]]:\n    \"\"\"Get the named parameters of the model\"\"\"\n    return super().named_parameters(prefix, recurse, remove_duplicate)\n</code></pre>"},{"location":"api/#decent_dp.ddp.DecentralizedDataParallel.global_avg","title":"<code>global_avg(will_revert=True, return_d2c=False)</code>","text":"<p>Perform global average of the model parameters across all workers</p> <p>Parameters:</p> Name Type Description Default <code>will_revert</code> <code>bool</code> <p>Whether to backup the parameters for reverting. Defaults to True.</p> <code>True</code> <code>return_d2c</code> <code>bool</code> <p>Whether to return the distance to center. Defaults to False.</p> <code>False</code> Source code in <code>src/decent_dp/ddp.py</code> <pre><code>@torch.no_grad()\ndef global_avg(self, will_revert: bool = True, return_d2c: bool = False) -&gt; Optional[float]:\n    \"\"\"Perform global average of the model parameters across all workers\n\n    Args:\n        will_revert (bool, optional): Whether to backup the parameters for reverting. Defaults to True.\n        return_d2c (bool, optional): Whether to return the distance to center. Defaults to False.\n    \"\"\"\n    for op in self._comm_ops:\n        if op is not None:\n            op.wait()\n    if not will_revert:\n        self._comm_ops = [None for _ in range(len(self._param_buckets))]\n\n    if will_revert or return_d2c:\n        if len(self._param_backups) == 0:\n            for i in range(len(self._params)):\n                self._param_backups.append(self._params[i].data.detach().clone())\n        else:\n            torch._foreach_copy_(self._param_backups, [x.data for x in self._params])\n\n    if self._param_as_bucket_view:\n        torch._foreach_div_(self._param_blocks, self._world_size)\n        for i in range(len(self._param_blocks)):\n            dist.all_reduce(self._param_blocks[i], op=dist.ReduceOp.SUM)\n    else:\n        torch._foreach_div_([x.data for x in self._params], self._world_size)\n        for x in self._params:\n            dist.all_reduce(x.data, op=dist.ReduceOp.SUM)\n\n    if self._sync_buffer_in_global_avg:\n        # globally average the float buffers (e.g. running mean and variance in batch normalization)\n        for x in self._model.buffers():\n            if x.dtype in self.FLOAT_DTYPES:\n                dist.all_reduce(x.data, op=dist.ReduceOp.SUM)\n                x.data.div_(self._world_size)\n\n    if return_d2c:\n        return torch.norm(\n            torch.stack(\n                torch._foreach_norm(torch._foreach_sub([x.data for x in self._params], self._param_backups))\n            )\n        ).item()\n</code></pre>"},{"location":"api/#decent_dp.ddp.DecentralizedDataParallel.revert_global_avg","title":"<code>revert_global_avg()</code>","text":"<p>Revert the parameters to the state before global average</p> Source code in <code>src/decent_dp/ddp.py</code> <pre><code>@torch.no_grad()\ndef revert_global_avg(self):\n    \"\"\"Revert the parameters to the state before global average\"\"\"\n    if len(self._param_backups) == 0:\n        raise RuntimeError(\"No backup found for reverting global average\")\n    torch._foreach_copy_([x.data for x in self._params], self._param_backups)\n</code></pre>"},{"location":"api/#decent_dp.ddp.DecentralizedDataParallel.get_lr","title":"<code>get_lr()</code>","text":"<p>Get the current learning rate from the first learning rate scheduler</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Current learning rate</p> Source code in <code>src/decent_dp/ddp.py</code> <pre><code>@torch.no_grad()\ndef get_lr(self) -&gt; float:\n    \"\"\"\n    Get the current learning rate from the first learning rate scheduler\n\n    Returns:\n        float: Current learning rate\n    \"\"\"\n    if self._initialized:\n        scheduler = self._lr_schedulers[0]\n        assert scheduler is not None, \"No learning rate scheduler is defined\"\n        return scheduler.get_last_lr()[0]\n    else:\n        return 0.0\n</code></pre>"},{"location":"api/#decent_dp.ddp.DecentralizedDataParallel.set_adaptive_factor","title":"<code>set_adaptive_factor(factor)</code>","text":"<p>Set the adaptive factor for scaling the model parameters during communication</p> <p>Parameters:</p> Name Type Description Default <code>factor</code> <code>float</code> <p>Adaptive factor</p> required Source code in <code>src/decent_dp/ddp.py</code> <pre><code>@torch.no_grad()\ndef set_adaptive_factor(self, factor: float):\n    \"\"\"Set the adaptive factor for scaling the model parameters during communication\n\n    Args:\n        factor (float): Adaptive factor\n    \"\"\"\n    self._adaptive_factor = factor\n</code></pre>"},{"location":"api/#decent_dpoptim","title":"decent_dp.optim","text":"<p>This module provides optimizer functions and custom optimizers designed specifically for decentralized training scenarios.</p>"},{"location":"api/#decent_dp.optim","title":"<code>decent_dp.optim</code>","text":""},{"location":"api/#decent_dp.optim.AccumAdamW","title":"<code>AccumAdamW</code>","text":"<p>               Bases: <code>Optimizer</code></p> <p>AccumAdamW optimizer</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>Any</code> <p>parameters list or groups</p> required <code>lr</code> <code>float</code> <p>base learning rate. Defaults to 1e-3.</p> <code>0.001</code> <code>betas</code> <code>Tuple[float, float]</code> <p>beta1 and beta2. Defaults to (0.9, 0.999).</p> <code>(0.9, 0.999)</code> <code>eps</code> <code>float</code> <p>epsilon. Defaults to 1e-8.</p> <code>1e-08</code> <code>weight_decay</code> <code>float</code> <p>weight decay. Defaults to 0.</p> <code>0</code> <code>accum_iter</code> <code>int</code> <p>number of accumulation steps. Defaults to 4. should be scaling up with the number of workers.</p> <code>4</code> Source code in <code>src/decent_dp/optim.py</code> <pre><code>class AccumAdamW(torch.optim.Optimizer):\n    \"\"\"AccumAdamW optimizer\n\n    Args:\n        params (Any): parameters list or groups\n        lr (float, optional): base learning rate. Defaults to 1e-3.\n        betas (Tuple[float, float], optional): beta1 and beta2. Defaults to (0.9, 0.999).\n        eps (float, optional): epsilon. Defaults to 1e-8.\n        weight_decay (float, optional): weight decay. Defaults to 0.\n        accum_iter (int, optional): number of accumulation steps. Defaults to 4. should be scaling up with the number of workers.\n    \"\"\"\n\n    def __init__(\n        self,\n        params: Any,\n        lr: float = 1e-3,\n        betas: Tuple[float, float] = (0.9, 0.999),\n        eps: float = 1e-8,\n        weight_decay: float = 0,\n        accum_iter: int = 4,\n    ):\n        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, accum_iter=accum_iter)\n        super().__init__(params, defaults)\n\n    def _init_group(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, accum_grads, state_steps):\n        for p in group[\"params\"]:\n            if p.grad is not None:\n                params_with_grad.append(p)\n                grads.append(p.grad)\n                state = self.state[p]\n                if len(state) == 0:\n                    state[\"step\"] = torch.tensor(0, dtype=torch.int64)\n                    state[\"exp_avg\"] = torch.zeros_like(p, memory_format=torch.preserve_format)\n                    state[\"exp_avg_sq\"] = torch.zeros_like(p, memory_format=torch.preserve_format)\n                    state[\"accum_grad\"] = torch.zeros_like(p, memory_format=torch.preserve_format)\n                exp_avgs.append(state[\"exp_avg\"])\n                exp_avg_sqs.append(state[\"exp_avg_sq\"])\n                accum_grads.append(state[\"accum_grad\"])\n                state_steps.append(state[\"step\"])\n\n    @torch.no_grad()\n    def step(self, closure=None):  # type: ignore\n        self._cuda_graph_capture_health_check()\n        assert closure is None\n\n        for group in self.param_groups:\n            params_with_grad = []\n            grads = []\n            exp_avgs = []\n            exp_avg_sqs = []\n            accum_grads = []\n            state_steps = []\n            beta1, beta2 = group[\"betas\"]\n\n            self._init_group(group, params_with_grad, grads, exp_avgs, exp_avg_sqs, accum_grads, state_steps)\n\n            if len(state_steps) == 0:\n                continue\n\n            accum_adamw_foreach(\n                params_with_grad,\n                grads,\n                exp_avgs,\n                exp_avg_sqs,\n                accum_grads,\n                state_steps,\n                beta1,\n                beta2,\n                group[\"lr\"],\n                group[\"weight_decay\"],\n                group[\"eps\"],\n                group[\"accum_iter\"],\n            )\n</code></pre>"},{"location":"api/#decent_dp.optim.AccumAdam","title":"<code>AccumAdam</code>","text":"<p>               Bases: <code>Optimizer</code></p> <p>AccumAdamW optimizer</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>Any</code> <p>parameters list or groups</p> required <code>lr</code> <code>float</code> <p>base learning rate. Defaults to 1e-3.</p> <code>0.001</code> <code>betas</code> <code>Tuple[float, float]</code> <p>beta1 and beta2. Defaults to (0.9, 0.999).</p> <code>(0.9, 0.999)</code> <code>eps</code> <code>float</code> <p>epsilon. Defaults to 1e-8.</p> <code>1e-08</code> <code>weight_decay</code> <code>float</code> <p>weight decay. Defaults to 0.</p> <code>0.0</code> <code>accum_iter</code> <code>int</code> <p>number of accumulation steps. Defaults to 4. should be scaling up with the number of workers.</p> <code>4</code> Source code in <code>src/decent_dp/optim.py</code> <pre><code>class AccumAdam(torch.optim.Optimizer):\n    \"\"\"AccumAdamW optimizer\n\n    Args:\n        params (Any): parameters list or groups\n        lr (float, optional): base learning rate. Defaults to 1e-3.\n        betas (Tuple[float, float], optional): beta1 and beta2. Defaults to (0.9, 0.999).\n        eps (float, optional): epsilon. Defaults to 1e-8.\n        weight_decay (float, optional): weight decay. Defaults to 0.\n        accum_iter (int, optional): number of accumulation steps. Defaults to 4. should be scaling up with the number of workers.\n    \"\"\"\n\n    def __init__(\n        self,\n        params: Any,\n        lr: float = 1e-3,\n        betas: Tuple[float, float] = (0.9, 0.999),\n        eps: float = 1e-8,\n        weight_decay: float = 0.0,\n        accum_iter: int = 4,\n    ):\n        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, accum_iter=accum_iter)\n        super().__init__(params, defaults)\n\n    def _init_group(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, accum_grads, state_steps):\n        for p in group[\"params\"]:\n            if p.grad is not None:\n                params_with_grad.append(p)\n                grads.append(p.grad)\n                state = self.state[p]\n                if len(state) == 0:\n                    state[\"step\"] = torch.tensor(0, dtype=torch.int64)\n                    state[\"exp_avg\"] = torch.zeros_like(p, memory_format=torch.preserve_format)\n                    state[\"exp_avg_sq\"] = torch.zeros_like(p, memory_format=torch.preserve_format)\n                    state[\"accum_grad\"] = torch.zeros_like(p, memory_format=torch.preserve_format)\n                exp_avgs.append(state[\"exp_avg\"])\n                exp_avg_sqs.append(state[\"exp_avg_sq\"])\n                accum_grads.append(state[\"accum_grad\"])\n                state_steps.append(state[\"step\"])\n\n    @torch.no_grad()\n    def step(self, closure=None):  # type: ignore\n        self._cuda_graph_capture_health_check()\n        assert closure is None, \"Closure is not supported\"\n\n        for group in self.param_groups:\n            params_with_grad = []\n            grads = []\n            exp_avgs = []\n            exp_avg_sqs = []\n            accum_grads = []\n            state_steps = []\n            beta1, beta2 = group[\"betas\"]\n\n            self._init_group(group, params_with_grad, grads, exp_avgs, exp_avg_sqs, accum_grads, state_steps)\n\n            if len(state_steps) == 0:\n                continue\n\n            accum_adam_foreach(\n                params_with_grad,\n                grads,\n                exp_avgs,\n                exp_avg_sqs,\n                accum_grads,\n                state_steps,\n                beta1,\n                beta2,\n                group[\"lr\"],\n                group[\"weight_decay\"],\n                group[\"eps\"],\n                group[\"accum_iter\"],\n            )\n</code></pre>"},{"location":"api/#decent_dp.optim.optim_fn_adam","title":"<code>optim_fn_adam(params, lr=0.001, beta1=0.9, beta2=0.999, weight_decay=1.0 / 32768, eps=1e-08)</code>","text":"<p>An example of a function that creates an Adam optimizer with the given parameters and their names.     To change the hyperparameters of the optimizer, you can wrap it with <code>functools.partial</code> and pass the new values.</p> <p>Returns:</p> Name Type Description <code>Optimizer</code> <code>Optimizer</code> <p>an Adam optimizer</p> Source code in <code>src/decent_dp/optim.py</code> <pre><code>def optim_fn_adam(\n    params: List[Tuple[str, Tensor]],\n    lr: float = 1e-3,\n    beta1: float = 0.9,\n    beta2: float = 0.999,\n    weight_decay: float = 1.0 / 32768,\n    eps: float = 1e-8,\n) -&gt; Optimizer:\n    \"\"\"An example of a function that creates an Adam optimizer with the given parameters and their names.\n        To change the hyperparameters of the optimizer, you can wrap it with `functools.partial` and pass the new values.\n\n    Returns:\n        Optimizer: an Adam optimizer\n    \"\"\"\n    return torch.optim.Adam(_get_param_groups(params, weight_decay), lr=lr, betas=(beta1, beta2), eps=eps)\n</code></pre>"},{"location":"api/#decent_dp.optim.optim_fn_adamw","title":"<code>optim_fn_adamw(params, lr=0.001, beta1=0.9, beta2=0.999, weight_decay=0.1, eps=1e-08)</code>","text":"<p>An example of a function that creates an AdamW optimizer with the given parameters and their names.     To change the hyperparameters of the optimizer, you can wrap it with <code>functools.partial</code> and pass the new values.</p> <p>Returns:</p> Name Type Description <code>Optimizer</code> <code>Optimizer</code> <p>an AdamW optimizer</p> Source code in <code>src/decent_dp/optim.py</code> <pre><code>def optim_fn_adamw(\n    params: List[Tuple[str, Tensor]],\n    lr: float = 1e-3,\n    beta1: float = 0.9,\n    beta2: float = 0.999,\n    weight_decay: float = 0.1,\n    eps: float = 1e-8,\n) -&gt; Optimizer:\n    \"\"\"An example of a function that creates an AdamW optimizer with the given parameters and their names.\n        To change the hyperparameters of the optimizer, you can wrap it with `functools.partial` and pass the new values.\n\n    Returns:\n        Optimizer: an AdamW optimizer\n    \"\"\"\n    return torch.optim.AdamW(_get_param_groups(params, weight_decay), lr=lr, betas=(beta1, beta2), eps=eps)\n</code></pre>"},{"location":"api/#decent_dp.optim.optim_fn_accum_adam","title":"<code>optim_fn_accum_adam(params, lr=0.001, beta1=0.9, beta2=0.999, eps=1e-08, weight_decay=1.0 / 32768, accum_iter=4)</code>","text":"<p>An example of a function that creates an AccumAdam optimizer with the given parameters and their names.     To change the hyperparameters of the optimizer, you can wrap it with <code>functools.partial</code> and pass the new values.</p> <p>Returns:</p> Name Type Description <code>Optimizer</code> <code>Optimizer</code> <p>an AccumAdam optimizer</p> Source code in <code>src/decent_dp/optim.py</code> <pre><code>def optim_fn_accum_adam(\n    params: List[Tuple[str, Tensor]],\n    lr: float = 1e-3,\n    beta1: float = 0.9,\n    beta2: float = 0.999,\n    eps: float = 1e-8,\n    weight_decay: float = 1.0 / 32768,\n    accum_iter: int = 4,\n) -&gt; Optimizer:\n    \"\"\"An example of a function that creates an AccumAdam optimizer with the given parameters and their names.\n        To change the hyperparameters of the optimizer, you can wrap it with `functools.partial` and pass the new values.\n\n    Returns:\n        Optimizer: an AccumAdam optimizer\n    \"\"\"\n    return AccumAdam(\n        _get_param_groups(params, weight_decay), lr=lr, betas=(beta1, beta2), eps=eps, accum_iter=accum_iter\n    )\n</code></pre>"},{"location":"api/#decent_dp.optim.optim_fn_accum_adamw","title":"<code>optim_fn_accum_adamw(params, lr=0.001, beta1=0.9, beta2=0.999, eps=1e-08, weight_decay=0.1, accum_iter=4)</code>","text":"<p>An example of a function that creates an AccumAdamW optimizer with the given parameters and their names.     To change the hyperparameters of the optimizer, you can wrap it with <code>functools.partial</code> and pass the new values.</p> <p>Returns:</p> Name Type Description <code>Optimizer</code> <code>Optimizer</code> <p>an AccumAdamW optimizer</p> Source code in <code>src/decent_dp/optim.py</code> <pre><code>def optim_fn_accum_adamw(\n    params: List[Tuple[str, Tensor]],\n    lr: float = 1e-3,\n    beta1: float = 0.9,\n    beta2: float = 0.999,\n    eps: float = 1e-8,\n    weight_decay: float = 0.1,\n    accum_iter: int = 4,\n) -&gt; Optimizer:\n    \"\"\"An example of a function that creates an AccumAdamW optimizer with the given parameters and their names.\n        To change the hyperparameters of the optimizer, you can wrap it with `functools.partial` and pass the new values.\n\n    Returns:\n        Optimizer: an AccumAdamW optimizer\n    \"\"\"\n    return AccumAdamW(\n        _get_param_groups(params, weight_decay), lr=lr, betas=(beta1, beta2), eps=eps, accum_iter=accum_iter\n    )\n</code></pre>"},{"location":"api/#decent_dp.optim.lr_scheduler_fn_cosine_with_warmup","title":"<code>lr_scheduler_fn_cosine_with_warmup(optimizer, t_max, t_warmup, cosine_eta_min=1e-06, warmup_decay=0.01)</code>","text":"<p>An example of a function that creates a learning rate scheduler that combines a warmup and a cosine annealing schedule.</p> <p>Returns:</p> Name Type Description <code>LRScheduler</code> <code>LRScheduler</code> <p>a learning rate scheduler with the linear warmup followed by the cosine annealing</p> Source code in <code>src/decent_dp/optim.py</code> <pre><code>def lr_scheduler_fn_cosine_with_warmup(\n    optimizer: Optimizer, t_max: int, t_warmup: int, cosine_eta_min: float = 1e-6, warmup_decay: float = 0.01\n) -&gt; LRScheduler:\n    \"\"\"An example of a function that creates a learning rate scheduler that combines a warmup and a cosine annealing schedule.\n\n    Returns:\n        LRScheduler: a learning rate scheduler with the linear warmup followed by the cosine annealing\n    \"\"\"\n    main_lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=t_max, eta_min=cosine_eta_min)\n    warmup_lr_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=warmup_decay, total_iters=t_warmup)\n    return torch.optim.lr_scheduler.SequentialLR(\n        optimizer, schedulers=[warmup_lr_scheduler, main_lr_scheduler], milestones=[t_warmup]\n    )\n</code></pre>"},{"location":"api/#decent_dp.optim.accum_adamw_foreach","title":"<code>accum_adamw_foreach(params, grads, exp_avgs, exp_avg_sqs, accum_grads, state_steps, beta1, beta2, lr, weight_decay, eps, accum_iter)</code>","text":"<p>Optimized version of AccumAdamW optimizer using torch._foreach TODO: fused kernel</p> Source code in <code>src/decent_dp/optim.py</code> <pre><code>def accum_adamw_foreach(\n    params: List[torch.Tensor],\n    grads: List[torch.Tensor],\n    exp_avgs: List[torch.Tensor],\n    exp_avg_sqs: List[torch.Tensor],\n    accum_grads: List[torch.Tensor],\n    state_steps: List[torch.Tensor],\n    beta1: float,\n    beta2: float,\n    lr: Union[float, torch.Tensor],\n    weight_decay: float,\n    eps: float,\n    accum_iter: int,\n):\n    \"\"\"Optimized version of AccumAdamW optimizer using torch._foreach\n    TODO: fused kernel\n    \"\"\"\n\n    torch._foreach_add_(state_steps, 1)\n    if weight_decay != 0:\n        torch._foreach_mul_(params, 1 - lr * weight_decay)\n\n    step = state_steps[0].item()\n    torch._foreach_add_(accum_grads, grads, alpha=1.0 / accum_iter)\n\n    _exp_avgs = torch._foreach_add(exp_avgs, grads, alpha=1 - beta1)\n    _exp_avg_sqs = torch._foreach_addcmul(exp_avg_sqs, grads, grads, value=1 - beta2)\n\n    bias_correction1 = 1 - beta1 ** ((step + accum_iter - 1) // accum_iter)\n    bias_correction2 = 1 - beta2 ** ((step + accum_iter - 1) // accum_iter)\n    step_size = lr / bias_correction1\n    bias_correction2_sqrt = math.sqrt(bias_correction2)\n\n    torch._foreach_sqrt_(_exp_avg_sqs)\n    torch._foreach_div_(_exp_avg_sqs, bias_correction2_sqrt)\n    torch._foreach_add_(_exp_avg_sqs, eps)\n    torch._foreach_addcdiv_(params, _exp_avgs, _exp_avg_sqs, value=-step_size)  # type: ignore\n\n    if step % accum_iter == 0:\n        torch._foreach_add_(exp_avgs, accum_grads, alpha=1 - beta1)\n        torch._foreach_mul_(exp_avgs, beta1)\n        torch._foreach_addcmul_(exp_avg_sqs, accum_grads, accum_grads, value=1 - beta2)\n        torch._foreach_mul_(exp_avg_sqs, beta2)\n        torch._foreach_zero_(accum_grads)\n</code></pre>"},{"location":"api/#decent_dp.optim.accum_adam_foreach","title":"<code>accum_adam_foreach(params, grads, exp_avgs, exp_avg_sqs, accum_grads, state_steps, beta1, beta2, lr, weight_decay, eps, accum_iter)</code>","text":"<p>Optimized version of AccumAdam optimizer using torch._foreach TODO: write a fused kernel for this</p> Source code in <code>src/decent_dp/optim.py</code> <pre><code>def accum_adam_foreach(\n    params: List[torch.Tensor],\n    grads: List[torch.Tensor],\n    exp_avgs: List[torch.Tensor],\n    exp_avg_sqs: List[torch.Tensor],\n    accum_grads: List[torch.Tensor],\n    state_steps: List[torch.Tensor],\n    beta1: float,\n    beta2: float,\n    lr: Union[float, torch.Tensor],\n    weight_decay: float,\n    eps: float,\n    accum_iter: int,\n):\n    \"\"\"Optimized version of AccumAdam optimizer using torch._foreach\n    TODO: write a fused kernel for this\n    \"\"\"\n    torch._foreach_add_(state_steps, 1)\n    if weight_decay != 0:\n        torch._foreach_add_(grads, params, alpha=weight_decay)\n\n    step = state_steps[0].item()\n    torch._foreach_add_(accum_grads, grads, alpha=1.0 / accum_iter)\n\n    _exp_avgs = torch._foreach_add(exp_avgs, grads, alpha=1 - beta1)\n    _exp_avg_sqs = torch._foreach_addcmul(exp_avg_sqs, grads, grads, value=1 - beta2)\n\n    bias_correction1 = 1 - beta1 ** ((step + accum_iter - 1) // accum_iter)\n    bias_correction2 = 1 - beta2 ** ((step + accum_iter - 1) // accum_iter)\n    step_size = lr / bias_correction1\n    bias_correction2_sqrt = math.sqrt(bias_correction2)\n\n    torch._foreach_sqrt_(_exp_avg_sqs)\n    torch._foreach_div_(_exp_avg_sqs, bias_correction2_sqrt)\n    torch._foreach_add_(_exp_avg_sqs, eps)\n    torch._foreach_addcdiv_(params, _exp_avgs, _exp_avg_sqs, value=-step_size)  # type: ignore\n\n    if step % accum_iter == 0:\n        torch._foreach_add_(exp_avgs, accum_grads, alpha=1 - beta1)\n        torch._foreach_mul_(exp_avgs, beta1)\n        torch._foreach_addcmul_(exp_avg_sqs, accum_grads, accum_grads, value=1 - beta2)\n        torch._foreach_mul_(exp_avg_sqs, beta2)\n        torch._foreach_zero_(accum_grads)\n</code></pre>"},{"location":"api/#decent_dptopo","title":"decent_dp.topo","text":"<p>This module contains the topology classes that define communication patterns between workers in decentralized training.</p>"},{"location":"api/#decent_dp.topo","title":"<code>decent_dp.topo</code>","text":""},{"location":"api/#decent_dp.topo.Edge","title":"<code>Edge</code>  <code>dataclass</code>","text":"<p>Edge class for defining communication patterns among workers.</p> <p>Weight defines the fraction of the message that each worker keeps. For example, if the weight is 0.3,         then the worker keeps 30% of its message and shares 70% with other workers.         $$x_i = w \\cdot x_i + \\frac{1}{|\\text{ranks}|}\\sum_{j \\in \\text{ranks}} x_j * (1 - w)$$.         The weight should be between 0 and 1 for convergence.</p> <p>Parameters:</p> Name Type Description Default <code>ranks</code> <code>List[int]</code> <p>List of ranks of workers that communicate in this edge</p> required <code>weight</code> <code>List[float]</code> <p>Weight for each worker in the edge</p> required <code>group</code> <code>Optional[ProcessGroup]</code> <p>Process group for the edge, which will be created by Topology class</p> <code>None</code> Source code in <code>src/decent_dp/topo.py</code> <pre><code>@dataclass\nclass Edge:\n    \"\"\"Edge class for defining communication patterns among workers.\n\n    Weight defines the fraction of the message that each worker keeps. For example, if the weight is 0.3, \\\n        then the worker keeps 30% of its message and shares 70% with other workers. \\\n        $$x_i = w \\\\cdot x_i + \\\\frac{1}{|\\\\text{ranks}|}\\\\sum_{j \\\\in \\\\text{ranks}} x_j * (1 - w)$$. \\\n        The weight should be between 0 and 1 for convergence.\n\n    Args:\n        ranks (List[int]): List of ranks of workers that communicate in this edge\n        weight (List[float]): Weight for each worker in the edge\n        group (Optional[ProcessGroup]): Process group for the edge, which will be created by Topology class\n    \"\"\"\n\n    ranks: List[int]\n    weight: float\n    group: Optional[ProcessGroup] = None\n</code></pre>"},{"location":"api/#decent_dp.topo.Topology","title":"<code>Topology</code>","text":"Source code in <code>src/decent_dp/topo.py</code> <pre><code>class Topology:\n    def __init__(self, local_world_size):\n        \"\"\"Topology class for defining communication patterns between workers.\n\n        The class is responsible for creating process groups for each edge in the topology.\n        The edges are defined as a list of lists of Edge objects, where each list of edges \\\n            corresponds to one iteration of the communication pattern.\n        The topology is defined by implementing the _get_topo_edges method, which should return \\\n            a list of lists of Edge objects. When creating a new topology, the method should be \\\n            implemented to return the edges for the topology. Usable variables are `self._world_size`, \\\n            `self._local_world_size`, and `self._n_nodes` for the number of processes, processes per node, \\\n            and number of nodes, respectively.\n        A valid topology is one where each node participates in exactly one communication in each iteration.\n\n        Args:\n            local_world_size (int): Number of processes in each node (added as argument for some testing \\\n                purposes, should be set as the environment variable LOCAL_WORLD_SIZE for normal cases)\n        \"\"\"\n\n        assert dist.is_available() and dist.is_initialized(), \"Distributed environment is not initialized\"\n        self._rank: int = dist.get_rank()\n        self._world_size = dist.get_world_size()\n        self._local_world_size = local_world_size\n        assert self._world_size % local_world_size == 0, (\n            f\"World size must be divisible by local world size, \\\n            but {self._world_size} is not divisible by {local_world_size}\"\n        )\n        self._n_nodes = self._world_size // local_world_size\n        self._registry: Dict[str, ProcessGroup] = {}\n        self._edges: List[Edge] = []\n        self._create_edges()\n\n    def _create_edges(self):\n        \"\"\"Create process groups for each \"edge\" (or group) in the topology\"\"\"\n        all_edges = self._get_topo_edges()\n        self._validate_edges(all_edges)\n\n        # Create default group\n        all_ranks = [i for i in range(self._world_size)]\n        self._registry[\"all\"] = cast(ProcessGroup, dist.new_group(all_ranks))\n\n        for idx in range(len(all_edges)):\n            for edge in all_edges[idx]:\n                identifier = str(edge.ranks)\n                if identifier not in self._registry:\n                    self._registry[identifier] = cast(ProcessGroup, dist.new_group(edge.ranks))\n                edge.group = self._registry[identifier]\n\n        for idx in range(len(all_edges)):\n            for edge in all_edges[idx]:\n                if self._rank in edge.ranks:\n                    self._edges.append(edge)\n                    break\n\n    def _validate_edges(self, edges: List[List[Edge]]):\n        \"\"\"Verify that the topology is valid. A valid topology is one where each \\\n            node participates in exactly communication in each iteration\n\n        Args:\n            edges (List[List[Edge]]): List of edges for each iteration\n        \"\"\"\n        for idx in range(len(edges)):\n            used = [False] * self._world_size\n            for edge in edges[idx]:\n                edge.ranks.sort()\n                for rank in edge.ranks:\n                    if used[rank]:\n                        logger.error(f\"Topology is not valid, node {rank} is used more than once in one iteration\")\n                        raise ValueError()\n                    used[rank] = True\n            if not all(used):\n                logger.error(\"Topology is not valid, some nodes are not involved in an edge in one iteration\")\n                raise ValueError()\n\n    def get_edge(self, step: int) -&gt; Edge:\n        \"\"\"Get the edge for the given iteration\"\"\"\n        return self._edges[step % len(self._edges)]\n\n    def _get_topo_edges(self) -&gt; List[List[Edge]]:\n        raise NotImplementedError()\n</code></pre>"},{"location":"api/#decent_dp.topo.Topology.__init__","title":"<code>__init__(local_world_size)</code>","text":"<p>Topology class for defining communication patterns between workers.</p> <p>The class is responsible for creating process groups for each edge in the topology. The edges are defined as a list of lists of Edge objects, where each list of edges             corresponds to one iteration of the communication pattern. The topology is defined by implementing the _get_topo_edges method, which should return             a list of lists of Edge objects. When creating a new topology, the method should be             implemented to return the edges for the topology. Usable variables are <code>self._world_size</code>,             <code>self._local_world_size</code>, and <code>self._n_nodes</code> for the number of processes, processes per node,             and number of nodes, respectively. A valid topology is one where each node participates in exactly one communication in each iteration.</p> <p>Parameters:</p> Name Type Description Default <code>local_world_size</code> <code>int</code> <p>Number of processes in each node (added as argument for some testing                 purposes, should be set as the environment variable LOCAL_WORLD_SIZE for normal cases)</p> required Source code in <code>src/decent_dp/topo.py</code> <pre><code>def __init__(self, local_world_size):\n    \"\"\"Topology class for defining communication patterns between workers.\n\n    The class is responsible for creating process groups for each edge in the topology.\n    The edges are defined as a list of lists of Edge objects, where each list of edges \\\n        corresponds to one iteration of the communication pattern.\n    The topology is defined by implementing the _get_topo_edges method, which should return \\\n        a list of lists of Edge objects. When creating a new topology, the method should be \\\n        implemented to return the edges for the topology. Usable variables are `self._world_size`, \\\n        `self._local_world_size`, and `self._n_nodes` for the number of processes, processes per node, \\\n        and number of nodes, respectively.\n    A valid topology is one where each node participates in exactly one communication in each iteration.\n\n    Args:\n        local_world_size (int): Number of processes in each node (added as argument for some testing \\\n            purposes, should be set as the environment variable LOCAL_WORLD_SIZE for normal cases)\n    \"\"\"\n\n    assert dist.is_available() and dist.is_initialized(), \"Distributed environment is not initialized\"\n    self._rank: int = dist.get_rank()\n    self._world_size = dist.get_world_size()\n    self._local_world_size = local_world_size\n    assert self._world_size % local_world_size == 0, (\n        f\"World size must be divisible by local world size, \\\n        but {self._world_size} is not divisible by {local_world_size}\"\n    )\n    self._n_nodes = self._world_size // local_world_size\n    self._registry: Dict[str, ProcessGroup] = {}\n    self._edges: List[Edge] = []\n    self._create_edges()\n</code></pre>"},{"location":"api/#decent_dp.topo.Topology.get_edge","title":"<code>get_edge(step)</code>","text":"<p>Get the edge for the given iteration</p> Source code in <code>src/decent_dp/topo.py</code> <pre><code>def get_edge(self, step: int) -&gt; Edge:\n    \"\"\"Get the edge for the given iteration\"\"\"\n    return self._edges[step % len(self._edges)]\n</code></pre>"},{"location":"api/#decent_dp.topo.CompleteTopology","title":"<code>CompleteTopology</code>","text":"<p>               Bases: <code>Topology</code></p> <p>Complete topology where each node communicates with all other nodes. The weights are 1/n.</p> Source code in <code>src/decent_dp/topo.py</code> <pre><code>@TopologyReg.register(\"complete\")\nclass CompleteTopology(Topology):\n    \"\"\"Complete topology where each node communicates with all other nodes. The weights are 1/n.\"\"\"\n\n    def _get_topo_edges(self) -&gt; List[List[Edge]]:\n        return [\n            [\n                Edge(\n                    ranks=list(range(self._world_size)),\n                    weight=1.0 / self._world_size,\n                )\n            ]\n        ]\n</code></pre>"},{"location":"api/#decent_dp.topo.RingTopology","title":"<code>RingTopology</code>","text":"<p>               Bases: <code>Topology</code></p> <p>One-peer ring topology where each node communicates with one of its left and right         neighbors (by index) in each iteration. The weights are 0.5 for each neighbor.</p> Source code in <code>src/decent_dp/topo.py</code> <pre><code>@TopologyReg.register(\"ring\")\nclass RingTopology(Topology):\n    \"\"\"One-peer ring topology where each node communicates with one of its left and right \\\n        neighbors (by index) in each iteration. The weights are 0.5 for each neighbor.\n    \"\"\"\n\n    def _get_topo_edges(self) -&gt; List[List[Edge]]:\n        if self._world_size % 2 != 0:\n            logger.error(\"Ring topology is not supported for odd world size\")\n            raise ValueError()\n\n        edges = [[], []]\n        # Odd iterations\n        for i in range(0, self._world_size, 2):\n            edges[0].append(Edge(ranks=sorted([i, (i + 1) % self._world_size]), weight=0.5))\n        # Even iterations\n        for i in range(0, self._world_size, 2):\n            edges[1].append(Edge(ranks=sorted([i, (i - 1 + self._world_size) % self._world_size]), weight=0.5))\n        return edges\n</code></pre>"},{"location":"api/#decent_dp.topo.OnePeerExpTopology","title":"<code>OnePeerExpTopology</code>","text":"<p>               Bases: <code>Topology</code></p> <p>One-peer exponential topology.</p> Source code in <code>src/decent_dp/topo.py</code> <pre><code>@TopologyReg.register(\"one-peer-exp\")\nclass OnePeerExpTopology(Topology):\n    \"\"\"One-peer exponential topology.\"\"\"\n\n    def _get_topo_edges(self) -&gt; List[List[Edge]]:\n        rounds = round(math.log2(self._world_size))\n        if self._world_size != 2**rounds:\n            logger.error(\"Exponential topology is only supported for 2^x world size\")\n            raise ValueError()\n\n        edges = []\n        for i in range(rounds):\n            edges.append([])\n            used = [False] * self._world_size\n            for j in range(self._world_size):\n                if not used[j]:\n                    used[j] = True\n                    used[(j + 2**i) % self._world_size] = True\n                    edges[i].append(Edge(ranks=sorted([j, (j + 2**i) % self._world_size]), weight=0.5))\n        return edges\n</code></pre>"},{"location":"api/#decent_dputils","title":"decent_dp.utils","text":"<p>Utility functions for setting up and managing the distributed training environment.</p>"},{"location":"api/#decent_dp.utils","title":"<code>decent_dp.utils</code>","text":""},{"location":"api/#decent_dp.utils.initialize_dist","title":"<code>initialize_dist()</code>","text":"<p>A utility function to initialize the distributed environment</p> <p>Returns:</p> Type Description <code>Tuple[int, int]</code> <p>Tuple[int, int]: rank and world size</p> Source code in <code>src/decent_dp/utils.py</code> <pre><code>def initialize_dist() -&gt; Tuple[int, int]:\n    \"\"\"A utility function to initialize the distributed environment\n\n    Returns:\n        Tuple[int, int]: rank and world size\n    \"\"\"\n\n    local_world_size = int(os.environ[\"LOCAL_WORLD_SIZE\"])\n    local_rank = int(os.environ[\"LOCAL_RANK\"])\n    gpus = os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"\")\n    if gpus:\n        if not (len(gpus.split(\",\")) == int(local_world_size)):\n            logger.error(\n                f\"LOCAL_WORLD_SIZE and CUDA_VISIBLE_DEVICES are not consistent, \\\n                         {local_world_size} vs {len(gpus.split(','))}\"\n            )\n            raise ValueError()\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpus.split(\",\")[local_rank]\n        dist.init_process_group(backend=\"nccl\")\n    else:\n        dist.init_process_group(backend=\"gloo\")\n    return dist.get_rank(), dist.get_world_size()\n</code></pre>"},{"location":"benchmarks/","title":"Benchmarks","text":"<p>This document presents performance benchmarks for Decent-DP compared to standard PyTorch DistributedDataParallel (DDP) and other decentralized training approaches.</p>"},{"location":"getting_started/","title":"Getting Started with Decent-DP","text":"<p>Decent-DP is a PyTorch extension that facilitates efficient multi-worker decentralized data parallel training. This guide will help you get started with installing and using Decent-DP in your projects.</p>"},{"location":"getting_started/#installation","title":"Installation","text":""},{"location":"getting_started/#prerequisites","title":"Prerequisites","text":"<p>Before installing Decent-DP, ensure you have the following prerequisites:</p> <ul> <li>Python 3.9 or higher</li> <li>PyTorch 2.1.0 or higher</li> <li>CUDA (for GPU training, optional but recommended)</li> </ul>"},{"location":"getting_started/#installation-methods","title":"Installation Methods","text":""},{"location":"getting_started/#via-pip-recommended","title":"Via pip (Recommended)","text":"<p>Install Decent-DP directly from PyPI:</p> <pre><code>pip install decent-dp\n</code></pre>"},{"location":"getting_started/#via-uv","title":"Via uv","text":"<p>If you're using uv as your package manager:</p> <pre><code>uv add decent-dp\n</code></pre>"},{"location":"getting_started/#from-source","title":"From Source","text":"<p>To install from source, clone the repository and install in editable mode:</p> <pre><code>git clone https://github.com/WangZesen/Decent-DP.git\ncd Decent-DP\npip install -e .\n</code></pre>"},{"location":"getting_started/#environment-setup","title":"Environment Setup","text":"<p>Decent-DP requires a properly configured distributed environment. You can either manually set up the environment variables or use the provided utility function.</p>"},{"location":"getting_started/#manual-setup","title":"Manual Setup","text":"<p>Set the following environment variables:</p> <pre><code>export LOCAL_WORLD_SIZE=&lt;number_of_processes_per_node&gt;\nexport LOCAL_RANK=&lt;local_process_rank&gt;\n</code></pre> <p>Then initialize the distributed process group:</p> <pre><code>import torch.distributed as dist\n\ndist.init_process_group(\n    backend='nccl' if torch.cuda.is_available() else 'gloo',\n    init_method='env://'\n)\n</code></pre>"},{"location":"getting_started/#using-utility-function","title":"Using Utility Function","text":"<p>Alternatively, use the provided utility function which automatically handles the setup:</p> <pre><code>from decent_dp.utils import initialize_dist\n\nrank, world_size = initialize_dist()\n</code></pre>"},{"location":"getting_started/#basic-usage-example","title":"Basic Usage Example","text":"<p>Here's a simple example to demonstrate how to use Decent-DP:</p> <pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom decent_dp.ddp import DecentralizedDataParallel as DecentDP\nfrom decent_dp.optim import optim_fn_adamw\n\n# Initialize model\nmodel = nn.Linear(10, 1).cuda()\n\n# Wrap model with DecentDP\nddp_model = DecentDP(\n    model,\n    optim_fn=optim_fn_adamw,\n    topology=\"complete\"\n)\n\n# Create dummy data\nx = torch.randn(32, 10).cuda()\ny = torch.randn(32, 1).cuda()\n\n# Forward pass\noutput = ddp_model(x)\nloss = nn.functional.mse_loss(output, y)\n\n# Backward pass\nddp_model.zero_grad()\nloss.backward()\n\n# Note: optimizer.step() is automatically called by DecentDP\n</code></pre>"},{"location":"getting_started/#running-distributed-training","title":"Running Distributed Training","text":"<p>To run your training script with multiple processes, use <code>torchrun</code>:</p> <pre><code>torchrun --nproc_per_node=4 your_training_script.py\n</code></pre> <p>For multi-node training, you'll also need to specify the master address and port:</p> <pre><code># On master node\ntorchrun --nproc_per_node=4 --nnodes=2 --node_rank=0 --master_addr=\"master.node.ip\" --master_port=12345 your_training_script.py\n\n# On worker node\ntorchrun --nproc_per_node=4 --nnodes=2 --node_rank=1 --master_addr=\"master.node.ip\" --master_port=12345 your_training_script.py\n</code></pre>"},{"location":"getting_started/#next-steps","title":"Next Steps","text":"<p>After getting familiar with the basic setup, explore these topics:</p> <ol> <li>Decentralized Data Parallel - Learn about the core DDP implementation</li> <li>Topology Design - Understand different communication topologies</li> <li>Custom Optimizers - Create your own optimizer functions compatible with Decent-DP</li> </ol> <p>For more advanced usage and performance benchmarks, check out our benchmark documentation.</p>"},{"location":"tutorials/custom_optimizers/","title":"Custom Optimizers Tutorial","text":"<p>Decent-DP provides specialized optimizers designed for decentralized training scenarios, particularly with gradient accumulation. This tutorial explains how to use the built-in optimizers and create your own custom optimizer functions.</p>"},{"location":"tutorials/custom_optimizers/#built-in-optimizers","title":"Built-in Optimizers","text":""},{"location":"tutorials/custom_optimizers/#standard-optimizers","title":"Standard Optimizers","text":"<p>Decent-DP includes wrapper functions for standard PyTorch optimizers:</p> <ul> <li><code>optim_fn_adam</code>: Adam optimizer with parameter grouping</li> <li><code>optim_fn_adamw</code>: AdamW optimizer with parameter grouping</li> </ul> <p>These functions automatically handle parameter grouping for weight decay:</p> <pre><code>from decent_dp.optim import optim_fn_adamw\n\n# Basic usage\nddp_model = DecentDP(model, optim_fn=optim_fn_adamw)\n\n# Customized hyperparameters\nfrom functools import partial\n\ncustom_adamw = partial(\n    optim_fn_adamw,\n    lr=0.001,\n    beta1=0.9,\n    beta2=0.999,\n    weight_decay=0.01,\n    eps=1e-8\n)\n\nddp_model = DecentDP(model, optim_fn=custom_adamw)\n</code></pre> <p>&lt;!-- ### Accumulated Gradient Optimizers</p> <p>For scenarios where you want to accumulate gradients over multiple steps before updating:</p> <ul> <li><code>optim_fn_accum_adam</code>: Adam optimizer with gradient accumulation</li> <li><code>optim_fn_accum_adamw</code>: AdamW optimizer with gradient accumulation</li> </ul> <p>These optimizers are designed to work with Decent-DP's gradient accumulation feature:</p> <pre><code>from decent_dp.optim import optim_fn_accum_adamw\n\n# With gradient accumulation\nddp_model = DecentDP(model, optim_fn=optim_fn_accum_adamw)\n\n# Enable gradient accumulation in training loop\nddp_model.set_accumulate_grad(True)\nfor i in range(accumulation_steps):\n    output = ddp_model(data)\n    loss = criterion(output, target) / accumulation_steps\n    loss.backward()\n\n# Disable gradient accumulation and perform update\nddp_model.set_accumulate_grad(False)\n``` --&gt;\n\n## Creating Custom Optimizer Functions\n\nOptimizer functions in Decent-DP must follow a specific signature:\n\n```python\ndef optimizer_function(params: List[Tuple[str, Tensor]]) -&gt; Optimizer:\n    \"\"\"Create an optimizer for the given parameters.\n\n    Args:\n        params: List of (parameter_name, parameter_tensor) tuples\n\n    Returns:\n        torch.optim.Optimizer: Configured optimizer instance\n    \"\"\"\n    # Extract parameter tensors\n    param_tensors = [p for _, p in params]\n\n    # Create and return optimizer\n    return torch.optim.YourOptimizer(param_tensors, your_hyperparameters)\n</code></pre>"},{"location":"tutorials/custom_optimizers/#example-custom-sgd-optimizer","title":"Example: Custom SGD Optimizer","text":"<pre><code>import torch\nfrom torch.optim import Optimizer\nfrom decent_dp.ddp import DecentralizedDataParallel as DecentDP\n\ndef optim_fn_sgd(params, lr=0.01, momentum=0.9, weight_decay=0.0):\n    \"\"\"Custom SGD optimizer function.\"\"\"\n    # Group parameters by weight decay (similar to built-in functions)\n    params_no_decay = [x for n, x in params if not ((\"bn\" in n) or (\"bias\" in n))]\n    params_decay = [x for n, x in params if (\"bn\" in n) or (\"bias\" in n)]\n\n    param_groups = [\n        {\"params\": params_no_decay, \"weight_decay\": 0.0},\n        {\"params\": params_decay, \"weight_decay\": weight_decay}\n    ]\n\n    return torch.optim.SGD(param_groups, lr=lr, momentum=momentum)\n\n# Use the custom optimizer function\nddp_model = DecentDP(model, optim_fn=optim_fn_sgd)\n</code></pre>"},{"location":"tutorials/custom_optimizers/#example-custom-adam-with-different-parameter-grouping","title":"Example: Custom Adam with Different Parameter Grouping","text":"<pre><code>def optim_fn_custom_adam(params, lr=1e-3, beta1=0.9, beta2=0.999, eps=1e-8):\n    \"\"\"Custom Adam optimizer with different parameter grouping logic.\"\"\"\n\n    # Group parameters based on their names\n    encoder_params = [x for n, x in params if \"encoder\" in n]\n    decoder_params = [x for n, x in params if \"decoder\" in n]\n\n    # Create parameter groups with different learning rates\n    param_groups = [\n        {\"params\": encoder_params, \"lr\": lr * 0.1},  # Encoder with lower LR\n        {\"params\": decoder_params, \"lr\": lr}        # Decoder with normal LR\n    ]\n\n    return torch.optim.Adam(param_groups, betas=(beta1, beta2), eps=eps)\n\n# Use the custom optimizer function\nddp_model = DecentDP(model, optim_fn=optim_fn_custom_adam)\n</code></pre>"},{"location":"tutorials/custom_optimizers/#working-with-learning-rate-schedulers","title":"Working with Learning Rate Schedulers","text":"<p>Decent-DP also supports learning rate schedulers through the <code>lr_scheduler_fn</code> parameter:</p> <pre><code>from decent_dp.optim import (\n    optim_fn_adamw,\n    lr_scheduler_fn_cosine_with_warmup\n)\n\n# Create model with optimizer and LR scheduler\nddp_model = DecentDP(\n    model,\n    optim_fn=optim_fn_adamw,\n    lr_scheduler_fn=lr_scheduler_fn_cosine_with_warmup\n)\n</code></pre>"},{"location":"tutorials/custom_optimizers/#custom-learning-rate-scheduler-function","title":"Custom Learning Rate Scheduler Function","text":"<pre><code>def custom_lr_scheduler_fn(optimizer, step_size=10, gamma=0.1):\n    \"\"\"Custom learning rate scheduler function.\"\"\"\n    return torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n\n# Use with custom scheduler\nddp_model = DecentDP(\n    model,\n    optim_fn=optim_fn_adamw,\n    lr_scheduler_fn=custom_lr_scheduler_fn\n)\n</code></pre>"},{"location":"tutorials/custom_optimizers/#advanced-optimizers-with-communication-awareness","title":"Advanced: Optimizers with Communication Awareness","text":"<p>Decent-DP allows optimizers to be aware of the communication topology through a special <code>pre_average_hook</code> method:</p> <pre><code>class TopologyAwareOptimizer(torch.optim.Optimizer):\n    def __init__(self, params, lr=0.01):\n        super().__init__(params, dict(lr=lr))\n\n    def pre_average_hook(self, edge, weight):\n        \"\"\"Called before parameter averaging in each iteration.\n\n        Args:\n            edge: Communication edge information\n            weight: Averaging weight for this worker\n        \"\"\"\n        # Adjust optimizer behavior based on communication topology\n        print(f\"Communicating with ranks {edge.ranks} using weight {weight}\")\n\n        # Example: Adjust learning rate based on communication pattern\n        for param_group in self.param_groups:\n            param_group['lr'] = self.defaults['lr'] * len(edge.ranks)\n</code></pre>"},{"location":"tutorials/custom_optimizers/#best-practices","title":"Best Practices","text":"<ol> <li>Parameter Grouping: Always consider how to group parameters for weight decay</li> <li>Hyperparameter Tuning: Decentralized training may require different hyperparameters than standard training</li> <li>Gradient Accumulation: Use accumulated gradient optimizers when simulating larger batch sizes</li> <li>Consistent Signatures: Ensure your optimizer functions follow the expected signature</li> <li>Testing: Test custom optimizers with simple models before using in production</li> </ol>"},{"location":"tutorials/custom_optimizers/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/custom_optimizers/#common-issues","title":"Common Issues","text":"<ol> <li>Optimizer Function Signature: Ensure your function takes <code>params: List[Tuple[str, Tensor]]</code> and returns an <code>Optimizer</code></li> <li>Parameter Grouping: Make sure all parameters are included in exactly one group</li> <li>Device Placement: Ensure parameters are on the correct device before creating optimizers</li> </ol>"},{"location":"tutorials/custom_optimizers/#debugging-tips","title":"Debugging Tips","text":"<p>Enable logging to see optimizer creation details:</p> <pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre> <p>This will show information about optimizer creation for each parameter bucket.</p>"},{"location":"tutorials/ddp/","title":"Decentralized Data Parallel (DDP) Tutorial","text":"<p>The <code>DecentralizedDataParallel</code> (DecentDP) class is the core component of the Decent-DP library. It wraps your PyTorch model to enable decentralized training across multiple workers without a central parameter server.</p>"},{"location":"tutorials/ddp/#overview","title":"Overview","text":"<p>Unlike PyTorch's standard <code>DistributedDataParallel</code> which relies on a centralized synchronization mechanism, DecentDP implements a fully decentralized approach where each worker communicates directly with its neighbors according to a specified topology.</p>"},{"location":"tutorials/ddp/#key-features","title":"Key Features","text":""},{"location":"tutorials/ddp/#parameter-bucketing","title":"Parameter Bucketing","text":"<p>DecentDP automatically groups model parameters into buckets based on size (default 25MB per bucket) to optimize communication efficiency. This is especially important in decentralized settings where communication patterns are more complex.</p>"},{"location":"tutorials/ddp/#gradient-accumulation-support","title":"Gradient Accumulation Support","text":"<p>The framework seamlessly handles gradient accumulation, which is crucial for simulating larger batch sizes in decentralized training scenarios.</p>"},{"location":"tutorials/ddp/#automatic-optimizer-management","title":"Automatic Optimizer Management","text":"<p>DecentDP creates and manages separate optimizers for each parameter bucket, automatically calling <code>step()</code> and <code>zero_grad()</code> at the appropriate times.</p>"},{"location":"tutorials/ddp/#initialization","title":"Initialization","text":"<p>To initialize DecentDP, you need to provide:</p> <ol> <li>Your model (already moved to the appropriate device)</li> <li>An optimizer function that creates optimizers for parameter groups</li> <li>(Optional) A learning rate scheduler function</li> <li>(Optional) Communication topology</li> </ol> <pre><code>from decent_dp.ddp import DecentralizedDataParallel as DecentDP\n\n# Basic initialization\nddp_model = DecentDP(\n    model,                    # Your PyTorch model (on GPU/CPU)\n    optim_fn,                 # Optimizer constructor function\n    lr_scheduler_fn=None,     # Optional LR scheduler constructor\n    topology=\"complete\",      # Communication topology\n    bucket_size_in_mb=25      # Size of parameter buckets\n)\n</code></pre>"},{"location":"tutorials/ddp/#optimizer-functions","title":"Optimizer Functions","text":"<p>DecentDP requires optimizer functions rather than direct optimizer instances because it manages multiple optimizers for different parameter buckets.</p>"},{"location":"tutorials/ddp/#predefined-optimizer-functions","title":"Predefined Optimizer Functions","text":"<p>The library provides several predefined optimizer functions:</p> <pre><code>from decent_dp.optim import (\n    optim_fn_adam,\n    optim_fn_adamw,\n    optim_fn_accum_adam,\n    optim_fn_accum_adamw\n)\n\n# Use directly\nddp_model = DecentDP(model, optim_fn=optim_fn_adamw)\n\n# Or customize hyperparameters with partial\nfrom functools import partial\n\ncustom_adamw = partial(\n    optim_fn_adamw,\n    lr=0.001,\n    weight_decay=0.01\n)\n\nddp_model = DecentDP(model, optim_fn=custom_adamw)\n</code></pre>"},{"location":"tutorials/ddp/#custom-optimizer-functions","title":"Custom Optimizer Functions","text":"<p>You can create your own optimizer functions:</p> <pre><code>def my_optim_fn(params):\n    \"\"\"Create a custom optimizer for the given parameters.\n\n    Args:\n        params: List of (name, tensor) tuples\n\n    Returns:\n        torch.optim.Optimizer: Configured optimizer instance\n    \"\"\"\n    return torch.optim.SGD(\n        [p for _, p in params],\n        lr=0.01,\n        momentum=0.9\n    )\n\nddp_model = DecentDP(model, optim_fn=my_optim_fn)\n</code></pre>"},{"location":"tutorials/ddp/#training-loop","title":"Training Loop","text":"<p>The training loop with DecentDP is similar to standard PyTorch but with some key differences:</p> <pre><code># Training loop\nfor epoch in range(num_epochs):\n    ddp_model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.cuda(), target.cuda()\n\n        # Forward pass\n        output = ddp_model(data)\n        loss = criterion(output, target)\n\n        # Backward pass\n        ddp_model.zero_grad()\n        loss.backward()\n        # Note: No need to call optimizer.step() - DecentDP handles this automatically\n\n    # Evaluation\n    ddp_model.eval()\n    with torch.no_grad():\n        for data, target in val_loader:\n            data, target = data.cuda(), target.cuda()\n            output = ddp_model(data)\n            val_loss = criterion(output, target)\n</code></pre>"},{"location":"tutorials/ddp/#gradient-accumulation","title":"Gradient Accumulation","text":"<p>To enable gradient accumulation:</p> <pre><code># Enable gradient accumulation\nddp_model.set_accumulate_grad(True)\n\n# Accumulate gradients over multiple batches\nfor i in range(accumulation_steps):\n    output = ddp_model(data)\n    loss = criterion(output, target) / accumulation_steps\n    loss.backward()\n\n# Disable gradient accumulation and perform update\nddp_model.set_accumulate_grad(False)\n</code></pre>"},{"location":"tutorials/ddp/#communication-topologies","title":"Communication Topologies","text":"<p>DecentDP supports various communication topologies that define how workers interact:</p> <ul> <li><code>complete</code>: All workers communicate with each other</li> <li><code>ring</code>: Workers form a ring and communicate with neighbors</li> <li><code>one-peer-exp</code>: Exponential communication pattern</li> <li><code>alternating-exp-ring</code>: Alternates between exponential and ring patterns</li> </ul> <p>For more details on topologies, see the Topology Design tutorial.</p>"},{"location":"tutorials/ddp/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"tutorials/ddp/#bucket-size","title":"Bucket Size","text":"<p>Control the size of parameter buckets for communication:</p> <pre><code>ddp_model = DecentDP(\n    model,\n    optim_fn=optim_fn_adamw,\n    bucket_size_in_mb=50  # Larger buckets for fewer communications\n)\n</code></pre>"},{"location":"tutorials/ddp/#gradient-clipping","title":"Gradient Clipping","text":"<p>Apply gradient clipping during training:</p> <pre><code>ddp_model = DecentDP(\n    model,\n    optim_fn=optim_fn_adamw,\n    grad_clip_norm=1.0  # Clip gradients to norm 1.0\n)\n</code></pre>"},{"location":"tutorials/ddp/#mixed-precision-training","title":"Mixed Precision Training","text":"<p>Use gradient scaling for mixed precision training:</p> <pre><code>from torch.cuda.amp import GradScaler\n\nscaler = GradScaler()\nddp_model = DecentDP(\n    model,\n    optim_fn=optim_fn_adamw,\n    scaler=scaler\n)\n</code></pre>"},{"location":"tutorials/ddp/#performance-considerations","title":"Performance Considerations","text":"<ol> <li>Bucket Size: Larger buckets reduce communication overhead but may increase memory usage</li> <li>Topology Selection: Different topologies have different communication and convergence characteristics</li> <li>Gradient Accumulation: Useful for simulating larger batch sizes without memory constraints</li> <li>Mixed Precision: Can significantly reduce memory usage and improve training speed</li> </ol>"},{"location":"tutorials/ddp/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/ddp/#common-issues","title":"Common Issues","text":"<ol> <li>\"Distributed environment is not initialized\": Make sure to call <code>dist.init_process_group()</code> before creating DecentDP instances</li> <li>Parameter order mismatch: Ensure all workers have the same model architecture and parameter ordering</li> <li>Memory issues: Try reducing bucket size or using gradient accumulation</li> </ol>"},{"location":"tutorials/ddp/#debugging-tips","title":"Debugging Tips","text":"<p>Enable logging to see detailed information about the initialization and training process:</p> <pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre> <p>This will show information about parameter bucketing, communication patterns, and other internal operations.</p>"},{"location":"tutorials/topology/","title":"Topology Design Tutorial","text":"<p>In decentralized training, the communication topology defines how workers interact with each other during the parameter averaging process. Decent-DP provides several built-in topologies and supports custom topology implementations.</p>"},{"location":"tutorials/topology/#understanding-topologies","title":"Understanding Topologies","text":"<p>A topology in Decent-DP is a communication pattern that determines: 1. Which workers communicate with each other in each iteration 2. The weight assigned to each worker's parameters during averaging</p> <p>The mathematical formulation for parameter averaging in Decent-DP is: $$x_i = w \\cdot x_i + \\frac{1-w}{|R|-1} \\sum_{j \\in R, j \\neq i} x_j$$</p> <p>Where: - $x_i$ is the parameter vector of worker $i$ - $w$ is the weight (between 0 and 1) - $R$ is the set of ranks participating in the communication</p>"},{"location":"tutorials/topology/#built-in-topologies","title":"Built-in Topologies","text":""},{"location":"tutorials/topology/#complete-topology","title":"Complete Topology","text":"<p>All workers communicate with each other in every iteration.</p> <pre><code>from decent_dp.ddp import DecentralizedDataParallel as DecentDP\n\nmodel = DecentDP(your_model, optim_fn, topology=\"complete\")\n</code></pre> <ul> <li>Weight: $1/\\text{world_size}$ for each worker</li> <li>Communication Pattern: Fully connected</li> <li>Use Case: Best for small clusters where all-to-all communication is feasible</li> </ul>"},{"location":"tutorials/topology/#ring-topology","title":"Ring Topology","text":"<p>Workers form a ring and communicate with one left and one right neighbor in alternating iterations.</p> <pre><code>model = DecentDP(your_model, optim_fn, topology=\"ring\")\n</code></pre> <ul> <li>Weight: 0.5 for each worker</li> <li>Communication Pattern: Ring-based, alternating directions</li> <li>Use Case: Good for large clusters where bandwidth is limited</li> </ul>"},{"location":"tutorials/topology/#one-peer-exponential-topology","title":"One-Peer Exponential Topology","text":"<p>Workers communicate with peers at exponentially increasing distances.</p> <pre><code>model = DecentDP(your_model, optim_fn, topology=\"one-peer-exp\")\n</code></pre> <ul> <li>Weight: 0.5 for each worker</li> <li>Communication Pattern: Exponential mixing</li> <li>Use Case: Fast mixing properties, good convergence rates</li> </ul>"},{"location":"tutorials/topology/#alternating-exponential-ring-topology","title":"Alternating Exponential-Ring Topology","text":"<p>Alternates between exponential and ring communication patterns.</p> <pre><code>model = DecentDP(your_model, optim_fn, topology=\"alternating-exp-ring\")\n</code></pre> <ul> <li>Weight: Varies by pattern</li> <li>Communication Pattern: Alternates between exp and ring</li> <li>Use Case: Combines benefits of both topologies</li> </ul>"},{"location":"tutorials/topology/#topology-selection-guide","title":"Topology Selection Guide","text":"Topology Communication Overhead Convergence Speed Memory Usage Best For Complete High (all-to-all) Fast Low Small clusters Ring Low Moderate Low Large clusters, bandwidth-limited environments One-Peer Exp Moderate Fast Low Medium clusters, when fast convergence is needed Alternating Exp-Ring Moderate Fast Low General purpose, combines benefits"},{"location":"tutorials/topology/#custom-topology-implementation","title":"Custom Topology Implementation","text":"<p>To implement a custom topology, extend the <code>Topology</code> base class:</p> <pre><code>from decent_dp.topo import Topology, Edge\n\nclass CustomTopology(Topology):\n    def _get_topo_edges(self) -&gt; List[List[Edge]]:\n        \"\"\"Define the communication edges for each iteration.\n\n        Returns:\n            List[List[Edge]]: A list of lists of Edge objects.\n            Each inner list represents one communication iteration.\n        \"\"\"\n        edges = []\n\n        # Example: Custom pattern with two iterations\n        # Iteration 1: Workers 0,1 communicate and 2,3 communicate\n        edges.append([\n            Edge(ranks=[0, 1], weight=0.5),\n            Edge(ranks=[2, 3], weight=0.5)\n        ])\n\n        # Iteration 2: Workers 0,2 communicate and 1,3 communicate\n        edges.append([\n            Edge(ranks=[0, 2], weight=0.5),\n            Edge(ranks=[1, 3], weight=0.5)\n        ])\n\n        return edges\n\n# Register the custom topology\nfrom decent_dp.topo import TopologyReg\nTopologyReg.registry[\"custom\"] = CustomTopology\n\n# Use the custom topology\nmodel = DecentDP(your_model, optim_fn, topology=\"custom\")\n</code></pre>"},{"location":"tutorials/topology/#performance-considerations","title":"Performance Considerations","text":"<ol> <li>Network Bandwidth: Choose topologies that match your network capabilities</li> <li>Cluster Size: Some topologies scale better with larger clusters</li> <li>Convergence Properties: Different topologies have different theoretical convergence rates</li> <li>Fault Tolerance: Decentralized topologies are inherently more fault-tolerant than centralized approaches</li> </ol>"},{"location":"tutorials/topology/#best-practices","title":"Best Practices","text":"<ol> <li>Start with Complete: For initial experiments and small clusters</li> <li>Use Ring for Large Clusters: When bandwidth is a concern</li> <li>Experiment with Exponential: For faster convergence when feasible</li> <li>Monitor Communication: Use profiling tools to understand communication patterns</li> <li>Validate Topology: Ensure your custom topology is valid (each node participates exactly once per iteration)</li> </ol>"},{"location":"tutorials/topology/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/topology/#common-issues","title":"Common Issues","text":"<ol> <li>Invalid Topology: Ensure each worker participates exactly once per iteration</li> <li>Process Group Creation: Make sure all ranks are properly initialized</li> <li>Weight Constraints: Weights should be between 0 and 1 for convergence</li> </ol>"},{"location":"tutorials/topology/#debugging-tips","title":"Debugging Tips","text":"<p>Enable debug logging to see topology information:</p> <pre><code>import logging\nfrom loguru import logger\n\nlogger.add(\"topology_debug.log\", level=\"DEBUG\")\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre> <p>This will show detailed information about the communication edges and process groups created for each topology.</p>"}]}